{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Team\n",
                "\n",
                "Shiref Khaled Elhalawany -  221100944\n",
                "\n",
                "Karim Ashraf Elsayed - 221100391\n",
                "\n",
                "Bassant Kamal Mesilam - 221100244 "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Section 2: Neighbhorhood CF Filters\n",
                "## 3.2.2. Part 2: Item-Based CF"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data Loading and Preparation\n",
                "\n",
                "This section imports the required libraries, defines the file paths, and loads the Electronics ratings dataset into a DataFrame.  \n",
                "It then builds two lookup structures:\n",
                "- `item_user_ratings`: maps each item to the users who rated it and their rating values  \n",
                "- `user_ratings_list`: stores a list of all ratings given by each user  \n",
                "\n",
                "Finally, it loads the item co-rating pairs from `3_1_13_co_rating_items.csv` into `df_co_items` for later item-based similarity calculations.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import math\n",
                "import csv\n",
                "import sys\n",
                "import os\n",
                "\n",
                "ratings_file = '../../dataset/Electronics.csv'\n",
                "co_rating_items_file = '../../results/3_1_13_co_rating_items.csv'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading ratings data...\n",
                        "Loaded 20994353 ratings.\n",
                        "Ratings dictionaries created.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Loading ratings data...\")\n",
                "df_ratings = pd.read_csv(ratings_file, header=None, names=[\"ItemID\", \"UserID\", \"Rating\", \"Timestamp\"])\n",
                "print(f\"Loaded {len(df_ratings)} ratings.\")\n",
                "\n",
                "item_user_ratings = {}\n",
                "\n",
                "user_ratings_list = {}\n",
                "\n",
                "for index, row in df_ratings.iterrows():\n",
                "    user = row['UserID']\n",
                "    item = row['ItemID']\n",
                "    rating = float(row['Rating'])\n",
                "    \n",
                "    if item not in item_user_ratings:\n",
                "        item_user_ratings[item] = {}\n",
                "    item_user_ratings[item][user] = rating\n",
                "    \n",
                "    if user not in user_ratings_list:\n",
                "        user_ratings_list[user] = []\n",
                "    user_ratings_list[user].append(rating)\n",
                "\n",
                "print(\"Ratings dictionaries created.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading co-rating items...\n",
                        "Loaded 73 pairs to calculate similarity for.\n",
                        "   TargetItem   OtherItem  CommonUsers\n",
                        "0  B000JE4594  B00000J060            1\n",
                        "1  B000JE4594  B00009MVK8            1\n",
                        "2  B000JE4594  B0001656FW            1\n",
                        "3  B000JE4594  B00029U0W2            1\n",
                        "4  B000JE4594  B0002H7F3G            1\n"
                    ]
                }
            ],
            "source": [
                "print(\"Loading co-rating items...\")\n",
                "df_co_items = pd.read_csv(co_rating_items_file)\n",
                "print(f\"Loaded {len(df_co_items)} pairs to calculate similarity for.\")\n",
                "print(df_co_items.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Case Study 1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.1.1\n",
                "\n",
                "This section first computes the average rating for each user using `compute_user_averages`.  \n",
                "\n",
                "It then calculates Adjusted Cosine Similarity between item pairs in `df_co_items` by subtracting each user’s average rating (user mean-centering) before computing similarity.  \n",
                "\n",
                "The results, including `TargetItem`, `OtherItem`, `Similarity`, and `CommonUsers`, are saved to:  \n",
                "`3_2_2_1_1_item_similarities.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_user_averages(user_ratings_list):\n",
                "    user_avgs = {}\n",
                "    for user, ratings in user_ratings_list.items():\n",
                "        if len(ratings) > 0:\n",
                "            user_avgs[user] = sum(ratings) / len(ratings)\n",
                "        else:\n",
                "            user_avgs[user] = 0.0\n",
                "    return user_avgs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_adjusted_cosine_similarity(item1, item2, item_user_ratings, user_avgs):\n",
                "    u1_users = item_user_ratings.get(item1, {})\n",
                "    u2_users = item_user_ratings.get(item2, {})\n",
                "    \n",
                "    common_users = set(u1_users.keys()) & set(u2_users.keys())\n",
                "    \n",
                "    if not common_users:\n",
                "        return 0.0, 0\n",
                "        \n",
                "    numerator = 0.0\n",
                "    sum_sq_1 = 0.0\n",
                "    sum_sq_2 = 0.0\n",
                "    \n",
                "    for user in common_users:\n",
                "        r1 = u1_users[user]\n",
                "        r2 = u2_users[user]\n",
                "        user_avg = user_avgs[user]\n",
                "        \n",
                "        r1_centered = r1 - user_avg\n",
                "        r2_centered = r2 - user_avg\n",
                "        \n",
                "        numerator += r1_centered * r2_centered\n",
                "        sum_sq_1 += r1_centered ** 2\n",
                "        sum_sq_2 += r2_centered ** 2\n",
                "        \n",
                "    norm1 = sum_sq_1 ** 0.5\n",
                "    norm2 = sum_sq_2 ** 0.5\n",
                "    \n",
                "    if norm1 == 0 or norm2 == 0:\n",
                "        return 0.0, len(common_users)\n",
                "        \n",
                "    similarity = numerator / (norm1 * norm2)\n",
                "    return similarity, len(common_users)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating user averages...\n",
                        "Calculated averages for 9838676 users.\n",
                        "Calculating item similarities...\n",
                        "Similarity calculation complete.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Calculating user averages...\")\n",
                "user_avgs = compute_user_averages(user_ratings_list)\n",
                "print(f\"Calculated averages for {len(user_avgs)} users.\")\n",
                "\n",
                "print(\"Calculating item similarities...\")\n",
                "similarities = []\n",
                "\n",
                "for index, row in df_co_items.iterrows():\n",
                "    target_item = row['TargetItem']\n",
                "    other_item = row['OtherItem']\n",
                "    \n",
                "    sim, num_common = calculate_adjusted_cosine_similarity(target_item, other_item, item_user_ratings, user_avgs)\n",
                "    \n",
                "    similarities.append({\n",
                "        'TargetItem': target_item,\n",
                "        'OtherItem': other_item,\n",
                "        'Similarity': round(sim, 2),\n",
                "        'CommonUsers': num_common\n",
                "    })\n",
                "\n",
                "print(\"Similarity calculation complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saving item-based adjusted cosine similarity results...\n",
                        "Results saved successfully.\n",
                        "   TargetItem   OtherItem  Similarity  CommonUsers\n",
                        "0  B000JE4594  B00000J060        -1.0            1\n",
                        "1  B000JE4594  B00009MVK8         1.0            1\n",
                        "2  B000JE4594  B0001656FW        -1.0            1\n",
                        "3  B000JE4594  B00029U0W2        -1.0            1\n",
                        "4  B000JE4594  B0002H7F3G        -1.0            1\n"
                    ]
                }
            ],
            "source": [
                "print(\"Saving item-based adjusted cosine similarity results...\")\n",
                "df_results = pd.DataFrame(similarities)\n",
                "output_file = '../../results/3_2_2_1_1_item_similarities.csv'\n",
                "df_results.to_csv(output_file, index=False)\n",
                "print(\"Results saved successfully.\")\n",
                "print(df_results.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.1.2\n",
                "\n",
                "This section groups similarity results by each target item, sorts them in descending order of Adjusted Cosine similarity, and selects the top 20% most similar items for each target item.  \n",
                "\n",
                "The selected item pairs are saved to:  \n",
                "`3_2_2_1_2_top_similar_items.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_top_n_similar_items(df_similarities, n_percentage=0.20, similarity_col='Similarity'):\n",
                "    top_similar_items = []\n",
                "\n",
                "    for target_item, group in df_similarities.groupby('TargetItem'):\n",
                "        sorted_group = group.sort_values(by=similarity_col, ascending=False)\n",
                "\n",
                "        n_top = math.ceil(len(sorted_group) * n_percentage)\n",
                "\n",
                "        top_items = sorted_group.head(n_top)\n",
                "\n",
                "        top_similar_items.append(top_items)\n",
                "\n",
                "    if top_similar_items:\n",
                "        return pd.concat(top_similar_items)\n",
                "    else:\n",
                "        return pd.DataFrame()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Identifying top 20% most similar items...\n",
                        "Identified 15 top similar item pairs.\n",
                        "Saving top 20% similar items to ../../results/3_2_2_1_2_top_similar_items.csv...\n",
                        "Top similar items saved successfully.\n",
                        "    TargetItem   OtherItem  Similarity  CommonUsers\n",
                        "37  B000JE4594  B00EZJZFDE         1.0            1\n",
                        "31  B000JE4594  B009GUL1VM         1.0            1\n",
                        "47  B000JE4594  B013HNYVCE         1.0            1\n",
                        "21  B000JE4594  B0043T7FXE         1.0            1\n",
                        "20  B000JE4594  B003S4ZJW4         1.0            1\n"
                    ]
                }
            ],
            "source": [
                "print(\"Identifying top 20% most similar items...\")\n",
                "\n",
                "df_top_similar_items = get_top_n_similar_items(df_results,n_percentage=0.20,similarity_col='Similarity')\n",
                "\n",
                "print(f\"Identified {len(df_top_similar_items)} top similar item pairs.\")\n",
                "\n",
                "top_items_output = '../../results/3_2_2_1_2_top_similar_items.csv'\n",
                "print(f\"Saving top 20% similar items to {top_items_output}...\")\n",
                "df_top_similar_items.to_csv(top_items_output, index=False)\n",
                "print(\"Top similar items saved successfully.\")\n",
                "print(df_top_similar_items.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.1.3\n",
                "\n",
                "This section defines an item-based prediction function that estimates unknown user ratings for target items using ratings on similar items weighted by their similarity scores. \n",
                " \n",
                "It then uses the top similar items (`df_top_similar_items`) and adjusted cosine similarity to generate predictions and saves them to:  \n",
                "`3_2_2_1_3_item_based_predictions.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_ratings_item_based(df_top_items, item_user_ratings, sim_col='Similarity'):\n",
                "    predictions = []\n",
                "\n",
                "    for target_item, group in df_top_items.groupby('TargetItem'):\n",
                "        target_item_users = set(item_user_ratings.get(target_item, {}).keys())\n",
                "\n",
                "        candidate_users = set()\n",
                "        for _, row in group.iterrows():\n",
                "            other_item = row['OtherItem']\n",
                "            other_item_users = item_user_ratings.get(other_item, {}).keys()\n",
                "            candidate_users.update(other_item_users)\n",
                "\n",
                "        unknown_users = candidate_users - target_item_users\n",
                "\n",
                "        for user in unknown_users:\n",
                "            numerator = 0.0\n",
                "            denominator = 0.0\n",
                "\n",
                "            for _, row in group.iterrows():\n",
                "                other_item = row['OtherItem']\n",
                "\n",
                "                similarity = row[sim_col]\n",
                "\n",
                "                rating = item_user_ratings.get(other_item, {}).get(user)\n",
                "\n",
                "                if rating is not None:\n",
                "                    numerator += similarity * rating\n",
                "                    denominator += abs(similarity)\n",
                "\n",
                "            if denominator > 0:\n",
                "                predicted_rating = numerator / denominator\n",
                "                predictions.append({\n",
                "                    'UserID': user,\n",
                "                    'Item': target_item,\n",
                "                    'PredictedRating': round(predicted_rating, 2),\n",
                "                    'SimilarityType': sim_col\n",
                "                })\n",
                "\n",
                "    return pd.DataFrame(predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting unknown ratings using item-based adjusted cosine similarity...\n",
                        "Generated 27558 item-based predictions.\n",
                        "Saving item-based predictions to ../../results/3_2_2_1_3_item_based_predictions.csv...\n",
                        "Item-based predictions saved successfully.\n",
                        "           UserID        Item  PredictedRating SimilarityType\n",
                        "0  A1D8WAI5CU9GLM  B000JE4594              4.0     Similarity\n",
                        "1  A2Z2H3G61MKN14  B000JE4594              3.0     Similarity\n",
                        "2  A1TKDREDLKIS4N  B000JE4594              5.0     Similarity\n",
                        "3  A3MRUWTJ8S3NM1  B000JE4594              5.0     Similarity\n",
                        "4  A2D0R3W70XF80I  B000JE4594              5.0     Similarity\n"
                    ]
                }
            ],
            "source": [
                "print(\"Predicting unknown ratings using item-based adjusted cosine similarity...\")\n",
                "\n",
                "df_predictions_items = predict_ratings_item_based(\n",
                "    df_top_similar_items, \n",
                "    item_user_ratings,\n",
                "    sim_col='Similarity'    \n",
                ")\n",
                "\n",
                "print(f\"Generated {len(df_predictions_items)} item-based predictions.\")\n",
                "\n",
                "predictions_items_file = '../../results/3_2_2_1_3_item_based_predictions.csv'\n",
                "print(f\"Saving item-based predictions to {predictions_items_file}...\")\n",
                "df_predictions_items.to_csv(predictions_items_file, index=False)\n",
                "print(\"Item-based predictions saved successfully.\")\n",
                "print(df_predictions_items.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.1.4\n",
                "\n",
                "This section computes Discounted Similarity (DS) for item-based collaborative filtering by scaling the adjusted cosine similarity with a discount factor based on how many users co-rated the item pair relative to a threshold β (30% of users who rated the target item).  \n",
                "\n",
                "The resulting discounted similarities are saved to:  \n",
                "`3_2_2_1_4_discounted_similarity_items.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_discounted_similarity_items(df_similarities, item_user_ratings, beta_pct=0.3, sim_col='Similarity'):\n",
                "    ds_list = []\n",
                "\n",
                "    for target_item, group in df_similarities.groupby('TargetItem'):\n",
                "        num_users_for_target = len(item_user_ratings.get(target_item, {}))\n",
                "\n",
                "        beta = math.ceil(num_users_for_target * beta_pct)\n",
                "\n",
                "        for _, row in group.iterrows():\n",
                "            other_item = row['OtherItem']\n",
                "            similarity = row[sim_col]\n",
                "            common_users = row['CommonUsers']\n",
                "\n",
                "            if beta > 0:\n",
                "                df = min(common_users / beta, 1.0)\n",
                "            else:\n",
                "                df = 1.0\n",
                "\n",
                "            ds = similarity * df\n",
                "\n",
                "            ds_entry = row.to_dict()\n",
                "            ds_entry['DiscountFactor'] = round(df, 2)\n",
                "            ds_entry['DiscountedSimilarity'] = round(ds, 2)\n",
                "\n",
                "            ds_list.append(ds_entry)\n",
                "\n",
                "    return pd.DataFrame(ds_list)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating Discounted Similarity for item-based adjusted cosine...\n",
                        "Item-based DS calculation complete.\n",
                        "   TargetItem   OtherItem  Similarity  CommonUsers  DiscountFactor  \\\n",
                        "0  B000JE4594  B00000J060        -1.0            1            0.11   \n",
                        "1  B000JE4594  B00009MVK8         1.0            1            0.11   \n",
                        "2  B000JE4594  B0001656FW        -1.0            1            0.11   \n",
                        "3  B000JE4594  B00029U0W2        -1.0            1            0.11   \n",
                        "4  B000JE4594  B0002H7F3G        -1.0            1            0.11   \n",
                        "\n",
                        "   DiscountedSimilarity  \n",
                        "0                 -0.11  \n",
                        "1                  0.11  \n",
                        "2                 -0.11  \n",
                        "3                 -0.11  \n",
                        "4                 -0.11  \n",
                        "Saving item-based Discounted Similarity to ../../results/3_2_2_1_4_discounted_similarity_items.csv...\n",
                        "Item-based Discounted Similarity saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Calculating Discounted Similarity for item-based adjusted cosine...\")\n",
                "\n",
                "df_ds_items = calculate_discounted_similarity_items(\n",
                "    df_results,    \n",
                "    item_user_ratings,\n",
                "    beta_pct=0.3,\n",
                "    sim_col='Similarity'    \n",
                ")\n",
                "\n",
                "print(\"Item-based DS calculation complete.\")\n",
                "print(df_ds_items.head())\n",
                "\n",
                "ds_items_output_file = '../../results/3_2_2_1_4_discounted_similarity_items.csv'\n",
                "print(f\"Saving item-based Discounted Similarity to {ds_items_output_file}...\")\n",
                "df_ds_items.to_csv(ds_items_output_file, index=False)\n",
                "print(\"Item-based Discounted Similarity saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.1.5\n",
                "\n",
                "This step selects the top 20% most similar items per target item using **Discounted Similarity** values computed earlier.  \n",
                "The output is saved to:  \n",
                "`3_2_2_1_5_top_similar_items_ds.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Identifying top 20% similar items based on Discounted Similarity...\n",
                        "Identified 15 top similar item pairs (DS).\n",
                        "Saving top 20% DS items to ../../results/3_2_2_1_5_top_similar_items_ds.csv...\n",
                        "Top DS items saved successfully.\n",
                        "    TargetItem   OtherItem  Similarity  CommonUsers  DiscountFactor  \\\n",
                        "37  B000JE4594  B00EZJZFDE         1.0            1            0.11   \n",
                        "31  B000JE4594  B009GUL1VM         1.0            1            0.11   \n",
                        "47  B000JE4594  B013HNYVCE         1.0            1            0.11   \n",
                        "21  B000JE4594  B0043T7FXE         1.0            1            0.11   \n",
                        "20  B000JE4594  B003S4ZJW4         1.0            1            0.11   \n",
                        "\n",
                        "    DiscountedSimilarity  \n",
                        "37                  0.11  \n",
                        "31                  0.11  \n",
                        "47                  0.11  \n",
                        "21                  0.11  \n",
                        "20                  0.11  \n"
                    ]
                }
            ],
            "source": [
                "print(\"Identifying top 20% similar items based on Discounted Similarity...\")\n",
                "\n",
                "df_top_ds_items = get_top_n_similar_items(\n",
                "    df_ds_items,                  \n",
                "    n_percentage=0.20,\n",
                "    similarity_col='DiscountedSimilarity'\n",
                ")\n",
                "\n",
                "print(f\"Identified {len(df_top_ds_items)} top similar item pairs (DS).\")\n",
                "\n",
                "ds_items_output_file = '../../results/3_2_2_1_5_top_similar_items_ds.csv'\n",
                "print(f\"Saving top 20% DS items to {ds_items_output_file}...\")\n",
                "df_top_ds_items.to_csv(ds_items_output_file, index=False)\n",
                "\n",
                "print(\"Top DS items saved successfully.\")\n",
                "print(df_top_ds_items.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.1.6\n",
                "\n",
                "This step predicts unknown user ratings for target items using **Discounted Similarity** from item-based collaborative filtering.  \n",
                "The prediction method considers only top 20% similar items per target item.  \n",
                "\n",
                "The output is saved to:  \n",
                "`3_2_2_1_6_item_based_predictions_ds.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting unknown ratings using Discounted Similarity (item-based)...\n",
                        "Generated 27558 item-based predictions (DS).\n",
                        "Saving item-based DS-based predictions to ../../results/3_2_2_1_6_item_based_predictions_ds.csv...\n",
                        "Item-based DS predictions saved successfully.\n",
                        "           UserID        Item  PredictedRating        SimilarityType\n",
                        "0  A1D8WAI5CU9GLM  B000JE4594              4.0  DiscountedSimilarity\n",
                        "1  A2Z2H3G61MKN14  B000JE4594              3.0  DiscountedSimilarity\n",
                        "2  A1TKDREDLKIS4N  B000JE4594              5.0  DiscountedSimilarity\n",
                        "3  A3MRUWTJ8S3NM1  B000JE4594              5.0  DiscountedSimilarity\n",
                        "4  A2D0R3W70XF80I  B000JE4594              5.0  DiscountedSimilarity\n"
                    ]
                }
            ],
            "source": [
                "print(\"Predicting unknown ratings using Discounted Similarity (item-based)...\")\n",
                "\n",
                "df_predictions_ds_items = predict_ratings_item_based(\n",
                "    df_top_ds_items,     \n",
                "    item_user_ratings,\n",
                "    sim_col='DiscountedSimilarity'\n",
                ")\n",
                "\n",
                "print(f\"Generated {len(df_predictions_ds_items)} item-based predictions (DS).\")\n",
                "\n",
                "predictions_ds_items_file = '../../results/3_2_2_1_6_item_based_predictions_ds.csv'\n",
                "print(f\"Saving item-based DS-based predictions to {predictions_ds_items_file}...\")\n",
                "df_predictions_ds_items.to_csv(predictions_ds_items_file, index=False)\n",
                "\n",
                "print(\"Item-based DS predictions saved successfully.\")\n",
                "print(df_predictions_ds_items.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Compare Results"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.1.7\n",
                "\n",
                "This step compares the top similar item lists obtained using standard adjusted cosine similarity and Discounted Similarity (DS) for each target item. \n",
                " \n",
                "It measures the overlap between both lists, saves detailed overlapping item pairs with similarity information to:  \n",
                "`3_2_2_1_7_overlap_items.csv`  \n",
                "and saves the summary comparison statistics per target item to:  \n",
                "`3_2_2_1_7_comparison_results_items.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing top items lists...\n",
                        "Average Overlap Percentage (items): 100.00%\n",
                        "   TargetItem  StandardCount  DSCount  OverlapCount  OverlapPercentage\n",
                        "0  B00L38GD2W              2        2             2              100.0\n",
                        "1  B000JE4594             13       13            13              100.0\n",
                        "Total overlapping (TargetItem, OtherItem) pairs: 15\n",
                        "   TargetItem   OtherItem\n",
                        "0  B00L38GD2W  B013XUS8WK\n",
                        "1  B00L38GD2W  B009657UWQ\n",
                        "2  B000JE4594  B000FJD5IA\n",
                        "3  B000JE4594  B00009V2XJ\n",
                        "4  B000JE4594  B013HNYVCE\n",
                        "Intersection items with details saved successfully to ../../results/3_2_2_1_7_overlap_items.csv.\n",
                        "   TargetItem   OtherItem  Similarity  CommonUsers  DiscountFactor  \\\n",
                        "0  B00L38GD2W  B013XUS8WK         1.0            1            0.25   \n",
                        "1  B00L38GD2W  B009657UWQ         1.0            1            0.25   \n",
                        "2  B000JE4594  B000FJD5IA         1.0            1            0.11   \n",
                        "3  B000JE4594  B00009V2XJ         1.0            1            0.11   \n",
                        "4  B000JE4594  B013HNYVCE         1.0            1            0.11   \n",
                        "\n",
                        "   DiscountedSimilarity  \n",
                        "0                  0.25  \n",
                        "1                  0.25  \n",
                        "2                  0.11  \n",
                        "3                  0.11  \n",
                        "4                  0.11  \n",
                        "Item-based comparison results saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Comparing top items lists...\")\n",
                "\n",
                "comparison_results_items = []\n",
                "overlap_item_pairs = []\n",
                "\n",
                "all_target_items = set(df_top_similar_items['TargetItem']).union(\n",
                "    set(df_top_ds_items['TargetItem'])\n",
                ")\n",
                "\n",
                "for target_item in all_target_items:\n",
                "    top_items_std = set(\n",
                "        df_top_similar_items[df_top_similar_items['TargetItem'] == target_item]['OtherItem']\n",
                "    )\n",
                "    top_items_ds = set(\n",
                "        df_top_ds_items[df_top_ds_items['TargetItem'] == target_item]['OtherItem']\n",
                "    )\n",
                "    \n",
                "    overlap = top_items_std.intersection(top_items_ds)\n",
                "    overlap_count = len(overlap)\n",
                "\n",
                "    for other_item in overlap:\n",
                "        overlap_item_pairs.append({\n",
                "            'TargetItem': target_item,\n",
                "            'OtherItem': other_item\n",
                "        })\n",
                "\n",
                "    comparison_results_items.append({\n",
                "        'TargetItem': target_item,\n",
                "        'StandardCount': len(top_items_std),\n",
                "        'DSCount': len(top_items_ds),\n",
                "        'OverlapCount': overlap_count,\n",
                "        'OverlapPercentage': round(overlap_count / len(top_items_std) * 100, 2)\n",
                "                            if len(top_items_std) > 0 else 0\n",
                "    })\n",
                "\n",
                "df_items_comparison = pd.DataFrame(comparison_results_items)\n",
                "print(f\"Average Overlap Percentage (items): {df_items_comparison['OverlapPercentage'].mean():.2f}%\")\n",
                "print(df_items_comparison.head())\n",
                "\n",
                "df_items_overlap_keys = pd.DataFrame(overlap_item_pairs)\n",
                "\n",
                "print(f\"Total overlapping (TargetItem, OtherItem) pairs: {len(df_items_overlap_keys)}\")\n",
                "print(df_items_overlap_keys.head())\n",
                "\n",
                "df_items_overlap_details = pd.merge(\n",
                "    df_items_overlap_keys,\n",
                "    df_ds_items,  \n",
                "    on=['TargetItem', 'OtherItem'],\n",
                "    how='left'\n",
                ")\n",
                "\n",
                "overlap_items_output_file = '../../results/3_2_2_1_7_overlap_items.csv'\n",
                "df_items_overlap_details.to_csv(overlap_items_output_file, index=False)\n",
                "print(f\"Intersection items with details saved successfully to {overlap_items_output_file}.\")\n",
                "print(df_items_overlap_details.head())\n",
                "\n",
                "comparison_items_output_file = '../../results/3_2_2_1_7_comparison_results_items.csv'\n",
                "df_items_comparison.to_csv(comparison_items_output_file, index=False)\n",
                "print(\"Item-based comparison results saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.1.8\n",
                "\n",
                "This step compares item-based rating predictions generated using standard adjusted cosine similarity and Discounted Similarity (DS).  \n",
                "\n",
                "It performs safety checks, merges common `(UserID, Item)` predictions, computes the difference between both methods, and saves the comparison results to:  \n",
                "`3_2_2_1_8_item_pred_comparison.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing item-based rating predictions...\n",
                        "Compared 27558 common item-based predictions.\n",
                        "Average Difference: 0.0000\n",
                        "           UserID        Item  PredictedRating_Std  PredictedRating_DS  \\\n",
                        "0  A1D8WAI5CU9GLM  B000JE4594                  4.0                 4.0   \n",
                        "1  A2Z2H3G61MKN14  B000JE4594                  3.0                 3.0   \n",
                        "2  A1TKDREDLKIS4N  B000JE4594                  5.0                 5.0   \n",
                        "3  A3MRUWTJ8S3NM1  B000JE4594                  5.0                 5.0   \n",
                        "4  A2D0R3W70XF80I  B000JE4594                  5.0                 5.0   \n",
                        "\n",
                        "   Difference  \n",
                        "0         0.0  \n",
                        "1         0.0  \n",
                        "2         0.0  \n",
                        "3         0.0  \n",
                        "4         0.0  \n",
                        "Item-based predictions comparison saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Comparing item-based rating predictions...\")\n",
                "\n",
                "required_cols = {'UserID', 'Item', 'PredictedRating'}\n",
                "\n",
                "if df_predictions_items.empty or df_predictions_ds_items.empty:\n",
                "    print(\"One of the prediction dataframes is EMPTY. Skipping comparison.\")\n",
                "    print(f\"df_predictions_items empty? {df_predictions_items.empty}\")\n",
                "    print(f\"df_predictions_ds_items empty? {df_predictions_ds_items.empty}\")\n",
                "else:\n",
                "\n",
                "    missing_std = required_cols - set(df_predictions_items.columns)\n",
                "    missing_ds  = required_cols - set(df_predictions_ds_items.columns)\n",
                "\n",
                "    if missing_std:\n",
                "        print(f\"Missing columns in df_predictions_items: {missing_std}\")\n",
                "    elif missing_ds:\n",
                "        print(f\"Missing columns in df_predictions_ds_items: {missing_ds}\")\n",
                "    else:\n",
                "\n",
                "        df_item_pred_comparison = pd.merge(\n",
                "            df_predictions_items[['UserID', 'Item', 'PredictedRating']],\n",
                "            df_predictions_ds_items[['UserID', 'Item', 'PredictedRating']],\n",
                "            on=['UserID', 'Item'],\n",
                "            suffixes=('_Std', '_DS'),\n",
                "            how='inner'\n",
                "        )\n",
                "\n",
                "        if df_item_pred_comparison.empty:\n",
                "            print(\"No overlapping (UserID, Item) predictions found.\")\n",
                "        else:\n",
                "            df_item_pred_comparison['Difference'] = (\n",
                "                df_item_pred_comparison['PredictedRating_Std']\n",
                "                - df_item_pred_comparison['PredictedRating_DS']\n",
                "            )\n",
                "\n",
                "            print(f\"Compared {len(df_item_pred_comparison)} common item-based predictions.\")\n",
                "            print(f\"Average Difference: {df_item_pred_comparison['Difference'].abs().mean():.4f}\")\n",
                "            print(df_item_pred_comparison.head())\n",
                "\n",
                "            pred_comp_items_file = '../../results/3_2_2_1_8_item_pred_comparison.csv'\n",
                "            df_item_pred_comparison.to_csv(pred_comp_items_file, index=False)\n",
                "\n",
                "            print(\"Item-based predictions comparison saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Case Study 2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.2.1\n",
                "This section defines a function to compute Pearson Correlation Coefficient (PCC) between item pairs based on common user ratings, then applies it to all co-rated item pairs in `df_co_items`.  \n",
                "\n",
                "The resulting item-based Pearson similarities are saved to:  \n",
                "`3_2_2_2_1_item_similarities_pearson.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_pearson_similarity_items(item1, item2, item_user_ratings):\n",
                "    i1_users = item_user_ratings.get(item1, {})\n",
                "    i2_users = item_user_ratings.get(item2, {})\n",
                "\n",
                "    common_users = set(i1_users.keys()) & set(i2_users.keys())\n",
                "\n",
                "    if not common_users:\n",
                "        return 0.0, 0\n",
                "\n",
                "    i1_ratings = [i1_users[u] for u in common_users]\n",
                "    i2_ratings = [i2_users[u] for u in common_users]\n",
                "\n",
                "    mean1 = sum(i1_ratings) / len(i1_ratings)\n",
                "    mean2 = sum(i2_ratings) / len(i2_ratings)\n",
                "\n",
                "    numerator = 0.0\n",
                "    denom1 = 0.0\n",
                "    denom2 = 0.0\n",
                "\n",
                "    for user in common_users:\n",
                "        d1 = i1_users[user] - mean1\n",
                "        d2 = i2_users[user] - mean2\n",
                "\n",
                "        numerator += d1 * d2\n",
                "        denom1 += d1 ** 2\n",
                "        denom2 += d2 ** 2\n",
                "\n",
                "    if denom1 == 0 or denom2 == 0:\n",
                "        return 0.0, len(common_users)\n",
                "\n",
                "    similarity = numerator / ((denom1 ** 0.5) * (denom2 ** 0.5))\n",
                "\n",
                "    return similarity, len(common_users)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating item-based Pearson (PCC) similarities...\n",
                        "Item-based Pearson similarity calculation complete.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Calculating item-based Pearson (PCC) similarities...\")\n",
                "pcc_item_similarities = []\n",
                "\n",
                "for index, row in df_co_items.iterrows():\n",
                "    target_item = row['TargetItem']\n",
                "    other_item = row['OtherItem']\n",
                "\n",
                "    sim, num_common = calculate_pearson_similarity_items(\n",
                "        target_item,\n",
                "        other_item,\n",
                "        item_user_ratings\n",
                "    )\n",
                "\n",
                "    pcc_item_similarities.append({\n",
                "        'TargetItem': target_item,\n",
                "        'OtherItem': other_item,\n",
                "        'PearsonSimilarity': round(sim, 2),\n",
                "        'CommonUsers': num_common\n",
                "    })\n",
                "\n",
                "print(\"Item-based Pearson similarity calculation complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saving item-based Pearson similarity results...\n",
                        "Item-based Pearson similarities saved successfully.\n",
                        "   TargetItem   OtherItem  PearsonSimilarity  CommonUsers\n",
                        "0  B000JE4594  B00000J060                0.0            1\n",
                        "1  B000JE4594  B00009MVK8                0.0            1\n",
                        "2  B000JE4594  B0001656FW                0.0            1\n",
                        "3  B000JE4594  B00029U0W2                0.0            1\n",
                        "4  B000JE4594  B0002H7F3G                0.0            1\n"
                    ]
                }
            ],
            "source": [
                "print(\"Saving item-based Pearson similarity results...\")\n",
                "df_pcc_item_results = pd.DataFrame(pcc_item_similarities)\n",
                "output_pcc_items = '../../results/3_2_2_2_1_item_similarities_pearson.csv'\n",
                "df_pcc_item_results.to_csv(output_pcc_items, index=False)\n",
                "print(\"Item-based Pearson similarities saved successfully.\")\n",
                "print(df_pcc_item_results.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.2.2\n",
                "\n",
                "This step selects the top 20% most similar items per target item using **Pearson Correlation** values. This helps identify items that users rate in a strongly related manner — even if their rating scales differ.\n",
                "\n",
                "The output is saved to:  \n",
                "`3_2_2_2_2_top_similar_items_pearson.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Identifying top 20% similar items based on Pearson similarity...\n",
                        "Identified 15 top similar item pairs (Pearson).\n",
                        "Saving top 20% Pearson similar items to ../../results/3_2_2_2_2_top_similar_items_pearson.csv...\n",
                        "Top 20% Pearson items saved successfully.\n",
                        "    TargetItem   OtherItem  PearsonSimilarity  CommonUsers\n",
                        "0   B000JE4594  B00000J060                0.0            1\n",
                        "33  B000JE4594  B00B86IKXO                0.0            1\n",
                        "35  B000JE4594  B00BVUNZUU                0.0            1\n",
                        "36  B000JE4594  B00C30HUQ2                0.0            1\n",
                        "37  B000JE4594  B00EZJZFDE                0.0            1\n"
                    ]
                }
            ],
            "source": [
                "print(\"Identifying top 20% similar items based on Pearson similarity...\")\n",
                "\n",
                "df_top_pcc_items = get_top_n_similar_items(\n",
                "    df_pcc_item_results,    \n",
                "    n_percentage=0.20,\n",
                "    similarity_col='PearsonSimilarity'\n",
                ")\n",
                "\n",
                "print(f\"Identified {len(df_top_pcc_items)} top similar item pairs (Pearson).\")\n",
                "\n",
                "top_pcc_items_output_file = '../../results/3_2_2_2_2_top_similar_items_pearson.csv'\n",
                "print(f\"Saving top 20% Pearson similar items to {top_pcc_items_output_file}...\")\n",
                "\n",
                "df_top_pcc_items.to_csv(top_pcc_items_output_file, index=False)\n",
                "\n",
                "print(\"Top 20% Pearson items saved successfully.\")\n",
                "print(df_top_pcc_items.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.2.3\n",
                "\n",
                "Using the top 20% of most similar items (based on **Pearson correlation**), we predict how users would rate items they have not rated before.\n",
                "\n",
                "Predicted results are saved to:  \n",
                "`3_2_2_2_3_item_based_predictions_pearson.csv`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting unknown ratings using item-based Pearson similarity...\n",
                        "Generated 0 item-based PCC predictions.\n",
                        "Saving item-based PCC predictions to ../../results/3_2_2_2_3_item_based_predictions_pearson.csv...\n",
                        "Item-based PCC predictions saved successfully.\n",
                        "Empty DataFrame\n",
                        "Columns: []\n",
                        "Index: []\n"
                    ]
                }
            ],
            "source": [
                "print(\"Predicting unknown ratings using item-based Pearson similarity...\")\n",
                "\n",
                "df_predictions_pcc_items = predict_ratings_item_based(\n",
                "    df_top_pcc_items,      \n",
                "    item_user_ratings,\n",
                "    sim_col='PearsonSimilarity'\n",
                ")\n",
                "\n",
                "print(f\"Generated {len(df_predictions_pcc_items)} item-based PCC predictions.\")\n",
                "\n",
                "predictions_pcc_items_file = '../../results/3_2_2_2_3_item_based_predictions_pearson.csv'\n",
                "print(f\"Saving item-based PCC predictions to {predictions_pcc_items_file}...\")\n",
                "\n",
                "df_predictions_pcc_items.to_csv(predictions_pcc_items_file, index=False)\n",
                "\n",
                "print(\"Item-based PCC predictions saved successfully.\")\n",
                "print(df_predictions_pcc_items.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.2.4\n",
                "\n",
                "In this step, we apply a **Discount Factor (DF)** to the Pearson similarity scores.  \n",
                "The discount depends on how many users rated both items compared to the total number of users who rated the target item.\n",
                "\n",
                "This reduces the impact of similarities computed over very few co-ratings  \n",
                "— improving reliability.\n",
                "\n",
                "The output is saved to:  \n",
                "`3_2_2_2_4_discounted_similarity_pearson_items.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating item-based Discounted Pearson Similarity...\n",
                        "Item-based PCC DS calculation complete.\n",
                        "   TargetItem   OtherItem  PearsonSimilarity  CommonUsers  DiscountFactor  \\\n",
                        "0  B000JE4594  B00000J060                0.0            1            0.11   \n",
                        "1  B000JE4594  B00009MVK8                0.0            1            0.11   \n",
                        "2  B000JE4594  B0001656FW                0.0            1            0.11   \n",
                        "3  B000JE4594  B00029U0W2                0.0            1            0.11   \n",
                        "4  B000JE4594  B0002H7F3G                0.0            1            0.11   \n",
                        "\n",
                        "   DiscountedSimilarity  \n",
                        "0                   0.0  \n",
                        "1                   0.0  \n",
                        "2                   0.0  \n",
                        "3                   0.0  \n",
                        "4                   0.0  \n",
                        "Saving item-based Discounted Pearson Similarity to ../../results/3_2_2_2_4_discounted_similarity_pearson_items.csv...\n",
                        "Item-based Discounted Pearson Similarity saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Calculating item-based Discounted Pearson Similarity...\")\n",
                "\n",
                "df_ds_pcc_items = calculate_discounted_similarity_items(\n",
                "    df_pcc_item_results,   \n",
                "    item_user_ratings,\n",
                "    beta_pct=0.3,\n",
                "    sim_col='PearsonSimilarity'\n",
                ")\n",
                "\n",
                "print(\"Item-based PCC DS calculation complete.\")\n",
                "print(df_ds_pcc_items.head())\n",
                "\n",
                "ds_pcc_items_output_file = '../../results/3_2_2_2_4_discounted_similarity_pearson_items.csv'\n",
                "print(f\"Saving item-based Discounted Pearson Similarity to {ds_pcc_items_output_file}...\")\n",
                "\n",
                "df_ds_pcc_items.to_csv(ds_pcc_items_output_file, index=False)\n",
                "\n",
                "print(\"Item-based Discounted Pearson Similarity saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.2.5\n",
                "\n",
                "This step selects the **top 20% most similar items** for each target item using **Discounted Pearson Similarity** scores.  \n",
                "\n",
                "The results are saved to:  \n",
                "`3_2_2_2_5_top_similar_items_pearson_ds.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Identifying top 20% similar items based on Discounted Pearson Similarity...\n",
                        "Identified 15 top similar item pairs (PCC DS).\n",
                        "Saving top 20% PCC DS items to ../../results/3_2_2_2_5_top_similar_items_pearson_ds.csv...\n",
                        "Top PCC DS items saved successfully.\n",
                        "    TargetItem   OtherItem  PearsonSimilarity  CommonUsers  DiscountFactor  \\\n",
                        "0   B000JE4594  B00000J060                0.0            1            0.11   \n",
                        "33  B000JE4594  B00B86IKXO                0.0            1            0.11   \n",
                        "35  B000JE4594  B00BVUNZUU                0.0            1            0.11   \n",
                        "36  B000JE4594  B00C30HUQ2                0.0            1            0.11   \n",
                        "37  B000JE4594  B00EZJZFDE                0.0            1            0.11   \n",
                        "\n",
                        "    DiscountedSimilarity  \n",
                        "0                    0.0  \n",
                        "33                   0.0  \n",
                        "35                   0.0  \n",
                        "36                   0.0  \n",
                        "37                   0.0  \n"
                    ]
                }
            ],
            "source": [
                "print(\"Identifying top 20% similar items based on Discounted Pearson Similarity...\")\n",
                "\n",
                "df_top_ds_pcc_items = get_top_n_similar_items(\n",
                "    df_ds_pcc_items,           \n",
                "    similarity_col='DiscountedSimilarity'\n",
                ")\n",
                "\n",
                "print(f\"Identified {len(df_top_ds_pcc_items)} top similar item pairs (PCC DS).\")\n",
                "\n",
                "top_ds_pcc_items_output_file = '../../results/3_2_2_2_5_top_similar_items_pearson_ds.csv'\n",
                "print(f\"Saving top 20% PCC DS items to {top_ds_pcc_items_output_file}...\")\n",
                "\n",
                "df_top_ds_pcc_items.to_csv(top_ds_pcc_items_output_file, index=False)\n",
                "\n",
                "print(\"Top PCC DS items saved successfully.\")\n",
                "print(df_top_ds_pcc_items.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.2.6\n",
                "\n",
                "In this step, we use **Discounted Pearson Similarity** to estimate how a user would rate items they have not rated yet.  \n",
                "\n",
                "The algorithm looks at similar items (top 20%) that the user has already rated and applies a weighted prediction formula.\n",
                "\n",
                "The results are saved to:  \n",
                "`3_2_2_2_6_item_based_predictions_pearson_ds.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting unknown ratings using Discounted Pearson Similarity (item-based)...\n",
                        "Generated 0 item-based PCC-DS predictions.\n",
                        "Saving item-based PCC-DS predictions to ../../results/3_2_2_2_6_item_based_predictions_pearson_ds.csv...\n",
                        "Item-based PCC-DS predictions saved successfully.\n",
                        "Empty DataFrame\n",
                        "Columns: []\n",
                        "Index: []\n"
                    ]
                }
            ],
            "source": [
                "print(\"Predicting unknown ratings using Discounted Pearson Similarity (item-based)...\")\n",
                "\n",
                "df_predictions_ds_pcc_items = predict_ratings_item_based(\n",
                "    df_top_ds_pcc_items,     \n",
                "    item_user_ratings,\n",
                "    sim_col='DiscountedSimilarity'\n",
                ")\n",
                "\n",
                "print(f\"Generated {len(df_predictions_ds_pcc_items)} item-based PCC-DS predictions.\")\n",
                "\n",
                "predictions_ds_pcc_items_file = '../../results/3_2_2_2_6_item_based_predictions_pearson_ds.csv'\n",
                "print(f\"Saving item-based PCC-DS predictions to {predictions_ds_pcc_items_file}...\")\n",
                "\n",
                "df_predictions_ds_pcc_items.to_csv(predictions_ds_pcc_items_file, index=False)\n",
                "\n",
                "print(\"Item-based PCC-DS predictions saved successfully.\")\n",
                "print(df_predictions_ds_pcc_items.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.2.7\n",
                "\n",
                "This step compares the **top 20% similar items** selected using:\n",
                "- **Pearson Similarity**\n",
                "- **Discounted Pearson Similarity**\n",
                "\n",
                "We calculate overlap between both item sets per target item and measure how much the ranking changed after discounting similarity.\n",
                "\n",
                "The results are saved to:\n",
                "\n",
                "1️-Overlap item pairs with full DS details:  \n",
                "`3_2_2_2_7_overlap_items_pearson.csv`\n",
                "\n",
                "2️- Summary comparison table (counts + percentages):  \n",
                "`3_2_2_2_7_comparison_results_items_pearson.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing top items lists (PCC)...\n",
                        "Average Overlap Percentage (Item-based PCC): 100.00%\n",
                        "   TargetItem  PCCCount  PCC_DSCount  OverlapCount  OverlapPercentage\n",
                        "0  B00L38GD2W         2            2             2              100.0\n",
                        "1  B000JE4594        13           13            13              100.0\n",
                        "Total overlapping (TargetItem, OtherItem) pairs (PCC): 15\n",
                        "   TargetItem   OtherItem\n",
                        "0  B00L38GD2W  B000CSSHG4\n",
                        "1  B00L38GD2W  B000R9BMVU\n",
                        "2  B000JE4594  B00XIHAHKA\n",
                        "3  B000JE4594  B00I8Y6V9E\n",
                        "4  B000JE4594  B00FSB799Q\n",
                        "Intersection items (PCC) with details saved successfully to ../../results/3_2_2_2_7_overlap_items_pearson.csv.\n",
                        "   TargetItem   OtherItem  PearsonSimilarity  CommonUsers  DiscountFactor  \\\n",
                        "0  B00L38GD2W  B000CSSHG4                0.0            1            0.25   \n",
                        "1  B00L38GD2W  B000R9BMVU                0.0            1            0.25   \n",
                        "2  B000JE4594  B00XIHAHKA                0.0            1            0.11   \n",
                        "3  B000JE4594  B00I8Y6V9E                0.0            1            0.11   \n",
                        "4  B000JE4594  B00FSB799Q                0.0            1            0.11   \n",
                        "\n",
                        "   DiscountedSimilarity  \n",
                        "0                   0.0  \n",
                        "1                   0.0  \n",
                        "2                   0.0  \n",
                        "3                   0.0  \n",
                        "4                   0.0  \n",
                        "Item-based PCC comparison results saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Comparing top items lists (PCC)...\")\n",
                "\n",
                "pcc_item_comparison_results = []\n",
                "pcc_item_overlap_pairs = []\n",
                "\n",
                "all_target_items_pcc = set(df_top_pcc_items['TargetItem']).union(\n",
                "    set(df_top_ds_pcc_items['TargetItem'])\n",
                ")\n",
                "\n",
                "for target_item in all_target_items_pcc:\n",
                "    top_items_pcc = set(\n",
                "        df_top_pcc_items[df_top_pcc_items['TargetItem'] == target_item]['OtherItem']\n",
                "    )\n",
                "    top_items_ds_pcc = set(\n",
                "        df_top_ds_pcc_items[df_top_ds_pcc_items['TargetItem'] == target_item]['OtherItem']\n",
                "    )\n",
                "    \n",
                "    overlap = top_items_pcc.intersection(top_items_ds_pcc)\n",
                "    overlap_count = len(overlap)\n",
                "\n",
                "    for other_item in overlap:\n",
                "        pcc_item_overlap_pairs.append({\n",
                "            'TargetItem': target_item,\n",
                "            'OtherItem': other_item\n",
                "        })\n",
                "\n",
                "    pcc_item_comparison_results.append({\n",
                "        'TargetItem': target_item,\n",
                "        'PCCCount': len(top_items_pcc),\n",
                "        'PCC_DSCount': len(top_items_ds_pcc),\n",
                "        'OverlapCount': overlap_count,\n",
                "        'OverlapPercentage': round(overlap_count / len(top_items_pcc) * 100, 2)\n",
                "                            if len(top_items_pcc) > 0 else 0\n",
                "    })\n",
                "\n",
                "df_pcc_items_comparison = pd.DataFrame(pcc_item_comparison_results)\n",
                "print(f\"Average Overlap Percentage (Item-based PCC): {df_pcc_items_comparison['OverlapPercentage'].mean():.2f}%\")\n",
                "print(df_pcc_items_comparison.head())\n",
                "\n",
                "df_pcc_items_overlap_keys = pd.DataFrame(pcc_item_overlap_pairs)\n",
                "\n",
                "print(f\"Total overlapping (TargetItem, OtherItem) pairs (PCC): {len(df_pcc_items_overlap_keys)}\")\n",
                "print(df_pcc_items_overlap_keys.head())\n",
                "\n",
                "df_pcc_items_overlap_details = pd.merge(\n",
                "    df_pcc_items_overlap_keys,\n",
                "    df_ds_pcc_items,   \n",
                "    on=['TargetItem', 'OtherItem'],\n",
                "    how='left'\n",
                ")\n",
                "\n",
                "overlap_pcc_items_output_file = '../../results/3_2_2_2_7_overlap_items_pearson.csv'\n",
                "df_pcc_items_overlap_details.to_csv(overlap_pcc_items_output_file, index=False)\n",
                "print(f\"Intersection items (PCC) with details saved successfully to {overlap_pcc_items_output_file}.\")\n",
                "print(df_pcc_items_overlap_details.head())\n",
                "\n",
                "comparison_pcc_items_output_file = '../../results/3_2_2_2_7_comparison_results_items_pearson.csv'\n",
                "df_pcc_items_comparison.to_csv(comparison_pcc_items_output_file, index=False)\n",
                "print(\"Item-based PCC comparison results saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.2.2.8\n",
                "\n",
                "This step compares the **predicted ratings** generated using:\n",
                "- **Pearson Similarity** (standard)\n",
                "- **Discounted Pearson Similarity (PCC-DS)**\n",
                "\n",
                "Only predictions that exist in **both** matrices (same User–Item pairs) are compared.  \n",
                "The comparison reveals change in prediction accuracy after applying the discount factor.\n",
                "\n",
                "Output file contains:\n",
                "- UserID, Item\n",
                "- Predicted Rating (PCC)\n",
                "- Predicted Rating (PCC-DS)\n",
                "- Absolute Difference\n",
                "\n",
                "Saved to:  \n",
                "`3_2_2_2_8_item_pred_comparison_pearson.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing item-based rating predictions (PCC)...\n",
                        "One of the prediction dataframes is EMPTY. Skipping comparison.\n",
                        "df_predictions_pcc_items empty? True\n",
                        "df_predictions_ds_pcc_items empty? True\n"
                    ]
                }
            ],
            "source": [
                "print(\"Comparing item-based rating predictions (PCC)...\")\n",
                "\n",
                "if df_predictions_pcc_items.empty or df_predictions_ds_pcc_items.empty:\n",
                "    print(\"One of the prediction dataframes is EMPTY. Skipping comparison.\")\n",
                "    print(f\"df_predictions_pcc_items empty? {df_predictions_pcc_items.empty}\")\n",
                "    print(f\"df_predictions_ds_pcc_items empty? {df_predictions_ds_pcc_items.empty}\")\n",
                "else:\n",
                "    required_cols = {'Item', 'UserID', 'PredictedRating'}\n",
                "    \n",
                "    missing_pcc = required_cols - set(df_predictions_pcc_items.columns)\n",
                "    missing_ds  = required_cols - set(df_predictions_ds_pcc_items.columns)\n",
                "\n",
                "    if missing_pcc:\n",
                "        print(f\"Missing columns in df_predictions_pcc_items: {missing_pcc}\")\n",
                "    elif missing_ds:\n",
                "        print(f\"Missing columns in df_predictions_ds_pcc_items: {missing_ds}\")\n",
                "    else:\n",
                "        df_item_pred_comparison_pcc = pd.merge(\n",
                "            df_predictions_pcc_items[['UserID', 'Item', 'PredictedRating']],\n",
                "            df_predictions_ds_pcc_items[['UserID', 'Item', 'PredictedRating']],\n",
                "            on=['UserID', 'Item'],\n",
                "            suffixes=('_PCC', '_PCC_DS'),\n",
                "            how='inner'\n",
                "        )\n",
                "\n",
                "        if df_item_pred_comparison_pcc.empty:\n",
                "            print(\"No common (UserID, Item) predictions to compare.\")\n",
                "        else:\n",
                "            df_item_pred_comparison_pcc['Difference'] = (\n",
                "                df_item_pred_comparison_pcc['PredictedRating_PCC']\n",
                "                - df_item_pred_comparison_pcc['PredictedRating_PCC_DS']\n",
                "            )\n",
                "\n",
                "            print(f\"Compared {len(df_item_pred_comparison_pcc)} item-based predictions (PCC).\")\n",
                "            print(f\"Average Difference: {df_item_pred_comparison_pcc['Difference'].abs().mean():.4f}\")\n",
                "            print(df_item_pred_comparison_pcc.head())\n",
                "\n",
                "            output_file = '../../results/3_2_2_2_8_item_pred_comparison_pearson.csv'\n",
                "            df_item_pred_comparison_pcc.to_csv(output_file, index=False)\n",
                "            print(f\"PCC item-based prediction comparison saved to {output_file}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
