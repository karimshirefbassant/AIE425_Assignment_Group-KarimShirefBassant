{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Team\n",
                "\n",
                "Shiref Khaled Elhalawany -  221100944\n",
                "\n",
                "Karim Ashraf Elsayed - 221100391\n",
                "\n",
                "Bassant Kamal Mesilam - 221100244 "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Section 2: Neighbhorhood CF Filters\n",
                "## 3.2.1. Part 1: User-Based CF"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data Loading and Preparation\n",
                "\n",
                "This section imports the required libraries, defines the input file paths, and loads the Electronics ratings dataset into a DataFrame.  \n",
                "\n",
                "It then builds a nested dictionary `user_item_ratings` that maps each user to the items they rated and their corresponding ratings.  \n",
                "\n",
                "Finally, it loads the co-rating user pairs from `3_1_13_co_rating_users.csv` into a DataFrame for later similarity calculations and prints a brief summary.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import math\n",
                "import csv\n",
                "import sys\n",
                "import os\n",
                "\n",
                "ratings_file = '../../dataset/Electronics.csv'\n",
                "co_rating_users_file = '../../results/3_1_13_co_rating_users.csv'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading ratings data...\n",
                        "Loaded 20994353 ratings.\n",
                        "Ratings dictionary created.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Loading ratings data...\")\n",
                "df_ratings = pd.read_csv(ratings_file, header=None, names=[\"ItemID\", \"UserID\", \"Rating\", \"Timestamp\"])\n",
                "print(f\"Loaded {len(df_ratings)} ratings.\")\n",
                "\n",
                "user_item_ratings = {}\n",
                "for index, row in df_ratings.iterrows():\n",
                "    user = row['UserID']\n",
                "    item = row['ItemID']\n",
                "    rating = float(row['Rating'])\n",
                "    \n",
                "    if user not in user_item_ratings:\n",
                "        user_item_ratings[user] = {}\n",
                "    user_item_ratings[user][item] = rating\n",
                "\n",
                "print(\"Ratings dictionary created.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading co-rating users...\n",
                        "Loaded 16305 pairs to calculate similarity for.\n",
                        "       TargetUser       OtherUser  CommonItems\n",
                        "0  A1ER5AYS3FQ9O3   AAP7PPBU72QFM            1\n",
                        "1  A1ER5AYS3FQ9O3   AIMPBO9K5SQ5X            1\n",
                        "2  A1ER5AYS3FQ9O3  A2QCVDCCZ3ABAC            1\n",
                        "3  A1ER5AYS3FQ9O3  A1C0Y8AFKTIRWY            1\n",
                        "4  A1ER5AYS3FQ9O3  A3M96C2MSACALP            1\n"
                    ]
                }
            ],
            "source": [
                "print(\"Loading co-rating users...\")\n",
                "df_co_users = pd.read_csv(co_rating_users_file)\n",
                "print(f\"Loaded {len(df_co_users)} pairs to calculate similarity for.\")\n",
                "print(df_co_users.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Case Study 1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.1.1\n",
                "\n",
                "This section defines a function `calculate_raw_cosine_similarity` to compute the cosine similarity between two users based on their common rated items.  \n",
                "\n",
                "It then iterates over all user pairs in `df_co_users`, calculates their similarity and number of common items, and stores the results in a DataFrame.  \n",
                "\n",
                "The full results are saved to:  \n",
                "`3_2_1_1_1_user_similarities.csv`  \n",
                "\n",
                "A filtered version, keeping only pairs with more than one common item, is saved to:  \n",
                "`3_2_1_1_1_user_similarities_filtered.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_raw_cosine_similarity(user1, user2, user_ratings):\n",
                "\n",
                "    u1_items = user_ratings.get(user1, {})\n",
                "    u2_items = user_ratings.get(user2, {})\n",
                "\n",
                "    common_items = set(u1_items.keys()) & set(u2_items.keys())\n",
                "\n",
                "    if not common_items:\n",
                "        return 0.0, 0\n",
                "\n",
                "    dot_product = 0.0\n",
                "    sum_sq_1 = 0.0\n",
                "    sum_sq_2 = 0.0\n",
                "\n",
                "    for item in common_items:\n",
                "        r1 = u1_items[item]\n",
                "        r2 = u2_items[item]\n",
                "\n",
                "        dot_product += r1 * r2\n",
                "        sum_sq_1 += r1 ** 2\n",
                "        sum_sq_2 += r2 ** 2\n",
                "\n",
                "    norm1 = sum_sq_1** 0.5\n",
                "    norm2 = sum_sq_2** 0.5\n",
                "\n",
                "    if norm1 == 0 or norm2 == 0:\n",
                "        return 0.0, len(common_items)\n",
                "\n",
                "    similarity = dot_product / (norm1 * norm2)\n",
                "    return similarity, len(common_items)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating similarities...\n",
                        "Similarity calculation complete.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Calculating similarities...\")\n",
                "similarities = []\n",
                "\n",
                "for index, row in df_co_users.iterrows():\n",
                "    target_user = row['TargetUser']\n",
                "    other_user = row['OtherUser']\n",
                "    \n",
                "    sim, num_common = calculate_raw_cosine_similarity(target_user, other_user, user_item_ratings)\n",
                "    \n",
                "    similarities.append({\n",
                "        'TargetUser': target_user,\n",
                "        'OtherUser': other_user,\n",
                "        'Similarity': round(sim, 2),\n",
                "        'CommonItems': num_common\n",
                "    })\n",
                "\n",
                "print(\"Similarity calculation complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saving results\n",
                        "Results saved successfully.\n",
                        "       TargetUser       OtherUser  Similarity  CommonItems\n",
                        "0  A1ER5AYS3FQ9O3   AAP7PPBU72QFM         1.0            1\n",
                        "1  A1ER5AYS3FQ9O3   AIMPBO9K5SQ5X         1.0            1\n",
                        "2  A1ER5AYS3FQ9O3  A2QCVDCCZ3ABAC         1.0            1\n",
                        "3  A1ER5AYS3FQ9O3  A1C0Y8AFKTIRWY         1.0            1\n",
                        "4  A1ER5AYS3FQ9O3  A3M96C2MSACALP         1.0            1\n",
                        "         TargetUser       OtherUser  Similarity  CommonItems\n",
                        "52   A1ER5AYS3FQ9O3  A2JCJJNY43QQIV        1.00            3\n",
                        "55   A1ER5AYS3FQ9O3   AM9APPMIE1BHZ        1.00            3\n",
                        "87   A1ER5AYS3FQ9O3  A37PV5GMP2ILJC        1.00            2\n",
                        "93   A1ER5AYS3FQ9O3  A259HHYBP6ZNJ3        0.99            2\n",
                        "124  A1ER5AYS3FQ9O3   A680RUE1FDO8B        0.99            2\n",
                        "Results saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Saving results\")\n",
                "df_results = pd.DataFrame(similarities)\n",
                "df_results.to_csv('../../results/3_2_1_1_1_user_similarities.csv', index=False)\n",
                "print(\"Results saved successfully.\")\n",
                "print(df_results.head())\n",
                "\n",
                "df_results_filtered = df_results[df_results['CommonItems'] > 1]\n",
                "print(df_results_filtered.head())\n",
                "df_results_filtered.to_csv('../../results/3_2_1_1_1_user_similarities_filtered.csv', index=False)\n",
                "print(\"Results saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.1.2\n",
                "\n",
                "This section defines a function that groups similarity results by each target user, sorts them by cosine similarity in descending order, and selects the top 20% most similar users for each target user.  \n",
                "\n",
                "The selected top pairs are combined into a single DataFrame and saved to:  \n",
                "`3_2_1_1_2_top_similar_users.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_top_n_similar_users(df_similarities, n_percentage=0.20, similarity_col='Similarity'):\n",
                "    top_similar_users = []\n",
                "\n",
                "    for target_user, group in df_similarities.groupby('TargetUser'):\n",
                "        sorted_group = group.sort_values(by=similarity_col, ascending=False)\n",
                "        \n",
                "        n_top = math.ceil(len(sorted_group) * n_percentage)\n",
                "        \n",
                "        top_users = sorted_group.head(n_top)\n",
                "        \n",
                "        top_similar_users.append(top_users)\n",
                "\n",
                "    if top_similar_users:\n",
                "        return pd.concat(top_similar_users)\n",
                "    else:\n",
                "        return pd.DataFrame()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Identifying top 20% similar users...\n",
                        "Identified 21 top similar users pairs.\n",
                        "Saving top 20% similar users to ../../results/3_2_1_1_2_top_similar_users.csv...\n",
                        "Top similar users saved successfully.\n",
                        "          TargetUser       OtherUser  Similarity  CommonItems\n",
                        "52    A1ER5AYS3FQ9O3  A2JCJJNY43QQIV         1.0            3\n",
                        "2688  A1ER5AYS3FQ9O3  A1KEK09ZA6J9P8         1.0            2\n",
                        "3589  A1ER5AYS3FQ9O3  A36AIK1DQPSRNT         1.0            2\n",
                        "3560  A1ER5AYS3FQ9O3  A2CVXUY1EYQGGA         1.0            3\n",
                        "3526  A1ER5AYS3FQ9O3   A5K5DIDKAML5C         1.0            2\n"
                    ]
                }
            ],
            "source": [
                "print(\"Identifying top 20% similar users...\")\n",
                "\n",
                "df_top_similar_users = get_top_n_similar_users(df_results_filtered, n_percentage=0.20, similarity_col='Similarity')\n",
                "\n",
                "print(f\"Identified {len(df_top_similar_users)} top similar users pairs.\")\n",
                "\n",
                "top_output_file = '../../results/3_2_1_1_2_top_similar_users.csv'\n",
                "print(f\"Saving top 20% similar users to {top_output_file}...\")\n",
                "df_top_similar_users.to_csv(top_output_file, index=False)\n",
                "print(\"Top similar users saved successfully.\")\n",
                "print(df_top_similar_users.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.1.3\n",
                "\n",
                "This section defines a function that predicts ratings for items not yet rated by each target user, using a weighted average of ratings from their top similar users (based on the chosen similarity column).  \n",
                "\n",
                "It generates a predictions DataFrame and saves the results to:  \n",
                "`3_2_1_1_3_predictions.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_ratings(df_top_users, user_item_ratings, sim_col='Similarity'):\n",
                "    predictions = []\n",
                "\n",
                "    for target_user, group in df_top_users.groupby('TargetUser'):\n",
                "        target_user_items = set(user_item_ratings.get(target_user, {}).keys())\n",
                "        \n",
                "        candidate_items = set()\n",
                "        for _, row in group.iterrows():\n",
                "            other_user = row['OtherUser']\n",
                "            other_user_items = user_item_ratings.get(other_user, {}).keys()\n",
                "            candidate_items.update(other_user_items)\n",
                "        \n",
                "        unknown_items = candidate_items - target_user_items\n",
                "        \n",
                "        for item in unknown_items:\n",
                "            numerator = 0.0\n",
                "            denominator = 0.0\n",
                "            \n",
                "            for _, row in group.iterrows():\n",
                "                other_user = row['OtherUser']\n",
                "                \n",
                "                similarity = row[sim_col]\n",
                "                \n",
                "                rating = user_item_ratings.get(other_user, {}).get(item)\n",
                "                \n",
                "                if rating is not None:\n",
                "                    numerator += similarity * rating\n",
                "                    denominator += abs(similarity)\n",
                "            \n",
                "            if denominator > 0:\n",
                "                predicted_rating = numerator / denominator\n",
                "                predictions.append({\n",
                "                    'TargetUser': target_user,\n",
                "                    'Item': item,\n",
                "                    'PredictedRating': round(predicted_rating, 2),\n",
                "                    'SimilarityType': sim_col\n",
                "                })\n",
                "                \n",
                "    return pd.DataFrame(predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting unknown ratings...\n",
                        "Generated 647 predictions.\n",
                        "Saving predictions to ../../results/3_2_1_1_3_predictions.csv...\n",
                        "Predictions saved successfully.\n",
                        "       TargetUser        Item  PredictedRating SimilarityType\n",
                        "0  A1ER5AYS3FQ9O3  B004Z74P0K              2.0     Similarity\n",
                        "1  A1ER5AYS3FQ9O3  B00BXJZ3KY              4.5     Similarity\n",
                        "2  A1ER5AYS3FQ9O3  B0072ZQGIG              4.0     Similarity\n",
                        "3  A1ER5AYS3FQ9O3  B01HCVG51M              4.0     Similarity\n",
                        "4  A1ER5AYS3FQ9O3  B000CDWNSW              5.0     Similarity\n"
                    ]
                }
            ],
            "source": [
                "print(\"Predicting unknown ratings...\")\n",
                "\n",
                "df_predictions = predict_ratings(df_top_similar_users, user_item_ratings, sim_col='Similarity')\n",
                "\n",
                "print(f\"Generated {len(df_predictions)} predictions.\")\n",
                "\n",
                "predictions_file = '../../results/3_2_1_1_3_predictions.csv'\n",
                "print(f\"Saving predictions to {predictions_file}...\")\n",
                "df_predictions.to_csv(predictions_file, index=False)\n",
                "print(\"Predictions saved successfully.\")\n",
                "print(df_predictions.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.1.4\n",
                "\n",
                "This part introduces a Discounted Similarity (DS) metric by adjusting cosine similarity using a discount factor based on the number of common items between users.  \n",
                "\n",
                "For each target user, a threshold β is computed as 30% of the number of items they rated. \n",
                "\n",
                "DS is then calculated as:   **DS = Similarity × DiscountFactor**,  \n",
                "and the results are saved to:  \n",
                "`3_2_1_1_4_discounted_similarity.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_discounted_similarity(df_similarities, user_item_ratings, beta_pct=0.3, sim_col='Similarity'):\n",
                "    ds_list = []\n",
                "\n",
                "    for target_user, group in df_similarities.groupby('TargetUser'):\n",
                "        num_rated_by_target = len(user_item_ratings.get(target_user, {}))\n",
                "        \n",
                "        beta = math.ceil(num_rated_by_target * beta_pct)\n",
                "        \n",
                "        for _, row in group.iterrows():\n",
                "            other_user = row['OtherUser']\n",
                "            similarity = row[sim_col]\n",
                "            common_items = row['CommonItems']\n",
                "            \n",
                "            if beta > 0:\n",
                "                df = min(common_items / beta, 1.0)\n",
                "            else:\n",
                "                df = 1.0 \n",
                "                \n",
                "            ds = similarity * df\n",
                "            \n",
                "            ds_entry = row.to_dict()\n",
                "            ds_entry['DiscountFactor'] = round(df, 2)\n",
                "            ds_entry['DiscountedSimilarity'] = round(ds, 2)\n",
                "            \n",
                "            ds_list.append(ds_entry)\n",
                "\n",
                "    return pd.DataFrame(ds_list)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating Discounted Similarity...\n",
                        "DS calculation complete.\n",
                        "       TargetUser       OtherUser  Similarity  CommonItems  DiscountFactor  \\\n",
                        "0  A1ER5AYS3FQ9O3  A2JCJJNY43QQIV        1.00            3            0.21   \n",
                        "1  A1ER5AYS3FQ9O3   AM9APPMIE1BHZ        1.00            3            0.21   \n",
                        "2  A1ER5AYS3FQ9O3  A37PV5GMP2ILJC        1.00            2            0.14   \n",
                        "3  A1ER5AYS3FQ9O3  A259HHYBP6ZNJ3        0.99            2            0.14   \n",
                        "4  A1ER5AYS3FQ9O3   A680RUE1FDO8B        0.99            2            0.14   \n",
                        "\n",
                        "   DiscountedSimilarity  \n",
                        "0                  0.21  \n",
                        "1                  0.21  \n",
                        "2                  0.14  \n",
                        "3                  0.14  \n",
                        "4                  0.14  \n",
                        "Saving Discounted Similarity to ../../results/3_2_1_1_4_discounted_similarity.csv...\n",
                        "Discounted Similarity saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Calculating Discounted Similarity...\")\n",
                "\n",
                "df_ds = calculate_discounted_similarity(df_results_filtered, user_item_ratings, beta_pct=0.3, sim_col='Similarity')\n",
                "\n",
                "print(\"DS calculation complete.\")\n",
                "print(df_ds.head())\n",
                "\n",
                "ds_output_file = '../../results/3_2_1_1_4_discounted_similarity.csv'\n",
                "print(f\"Saving Discounted Similarity to {ds_output_file}...\")\n",
                "df_ds.to_csv(ds_output_file, index=False)\n",
                "print(\"Discounted Similarity saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.1.5\n",
                "\n",
                "This section selects the top 20% most similar users for each target user using the Discounted Similarity (DS) values.  \n",
                "\n",
                "The filtered top-similar pairs are saved to:  \n",
                "`3_2_1_1_5_top_similar_users_ds.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Identifying top 20% similar users based on DS...\n",
                        "Identified 21 top similar users pairs (DS).\n",
                        "Saving top 20% DS users to ../../results/3_2_1_1_5_top_similar_users_ds.csv...\n",
                        "Top DS users saved successfully.\n",
                        "        TargetUser       OtherUser  Similarity  CommonItems  DiscountFactor  \\\n",
                        "58  A1ER5AYS3FQ9O3  A3R19YKNL641X3        0.98            4            0.29   \n",
                        "0   A1ER5AYS3FQ9O3  A2JCJJNY43QQIV        1.00            3            0.21   \n",
                        "14  A1ER5AYS3FQ9O3  A3OXHLG6DIBRW8        0.99            3            0.21   \n",
                        "1   A1ER5AYS3FQ9O3   AM9APPMIE1BHZ        1.00            3            0.21   \n",
                        "48  A1ER5AYS3FQ9O3  A240FRPD4MEXND        0.99            3            0.21   \n",
                        "\n",
                        "    DiscountedSimilarity  \n",
                        "58                  0.28  \n",
                        "0                   0.21  \n",
                        "14                  0.21  \n",
                        "1                   0.21  \n",
                        "48                  0.21  \n"
                    ]
                }
            ],
            "source": [
                "print(\"Identifying top 20% similar users based on DS...\")\n",
                "\n",
                "df_top_ds_users = get_top_n_similar_users(df_ds, n_percentage=0.20, similarity_col='DiscountedSimilarity')\n",
                "\n",
                "print(f\"Identified {len(df_top_ds_users)} top similar users pairs (DS).\")\n",
                "\n",
                "ds_output_file = '../../results/3_2_1_1_5_top_similar_users_ds.csv'\n",
                "print(f\"Saving top 20% DS users to {ds_output_file}...\")\n",
                "df_top_ds_users.to_csv(ds_output_file, index=False)\n",
                "print(\"Top DS users saved successfully.\")\n",
                "print(df_top_ds_users.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.1.6\n",
                "\n",
                "This section predicts unrated item scores using the top similar users identified via Discounted Similarity (DS).  \n",
                "\n",
                "The generated prediction results are saved into:  \n",
                "`3_2_1_1_6_predictions_ds.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting unknown ratings using Discounted Similarity...\n",
                        "Generated 1846 predictions (DS).\n",
                        "Saving DS-based predictions to ../../results/3_2_1_1_6_predictions_ds.csv...\n",
                        "DS-based predictions saved successfully.\n",
                        "       TargetUser        Item  PredictedRating        SimilarityType\n",
                        "0  A1ER5AYS3FQ9O3  B00MCVPIJI              3.0  DiscountedSimilarity\n",
                        "1  A1ER5AYS3FQ9O3  B000ND75BG              5.0  DiscountedSimilarity\n",
                        "2  A1ER5AYS3FQ9O3  B005ZG0IME              2.0  DiscountedSimilarity\n",
                        "3  A1ER5AYS3FQ9O3  B01FFRD1NU              5.0  DiscountedSimilarity\n",
                        "4  A1ER5AYS3FQ9O3  B00213QXFA              4.0  DiscountedSimilarity\n"
                    ]
                }
            ],
            "source": [
                "print(\"Predicting unknown ratings using Discounted Similarity...\")\n",
                "\n",
                "df_predictions_ds = predict_ratings(df_top_ds_users, user_item_ratings, sim_col='DiscountedSimilarity')\n",
                "\n",
                "print(f\"Generated {len(df_predictions_ds)} predictions (DS).\")\n",
                "\n",
                "predictions_ds_file = '../../results/3_2_1_1_6_predictions_ds.csv'\n",
                "print(f\"Saving DS-based predictions to {predictions_ds_file}...\")\n",
                "df_predictions_ds.to_csv(predictions_ds_file, index=False)\n",
                "print(\"DS-based predictions saved successfully.\")\n",
                "print(df_predictions_ds.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Compare Results"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.1.7\n",
                "\n",
                "This section compares the top similar users selected using standard cosine similarity and Discounted Similarity (DS) for each target user.  \n",
                "\n",
                "It computes the overlap between both top-user lists, summarizes the overlap statistics in a DataFrame, and saves:\n",
                "\n",
                "- Detailed overlapping (TargetUser, OtherUser) pairs with similarity information to:  \n",
                "  `3_2_1_1_7_overlap_users.csv`  \n",
                "  \n",
                "- Overall comparison metrics per target user to:  \n",
                "  `3_2_1_1_7_comparison_results.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing top users lists...\n",
                        "Average Overlap Percentage: 38.10%\n",
                        "       TargetUser  StandardCount  DSCount  OverlapCount  OverlapPercentage\n",
                        "0  A1ER5AYS3FQ9O3             21       21             8               38.1\n",
                        "Total overlapping (TargetUser, OtherUser) pairs: 8\n",
                        "       TargetUser       OtherUser\n",
                        "0  A1ER5AYS3FQ9O3  A2CVXUY1EYQGGA\n",
                        "1  A1ER5AYS3FQ9O3  A1KEK09ZA6J9P8\n",
                        "2  A1ER5AYS3FQ9O3   AJKWF4W7QD4NS\n",
                        "3  A1ER5AYS3FQ9O3   A5K5DIDKAML5C\n",
                        "4  A1ER5AYS3FQ9O3  A316XO4RWX21YN\n",
                        "Intersection users with details saved successfully to ../../results/3_2_1_1_7_overlap_users.csv.\n",
                        "       TargetUser       OtherUser  Similarity  CommonItems  DiscountFactor  \\\n",
                        "0  A1ER5AYS3FQ9O3  A2CVXUY1EYQGGA         1.0            3            0.21   \n",
                        "1  A1ER5AYS3FQ9O3  A1KEK09ZA6J9P8         1.0            2            0.14   \n",
                        "2  A1ER5AYS3FQ9O3   AJKWF4W7QD4NS         1.0            2            0.14   \n",
                        "3  A1ER5AYS3FQ9O3   A5K5DIDKAML5C         1.0            2            0.14   \n",
                        "4  A1ER5AYS3FQ9O3  A316XO4RWX21YN         1.0            2            0.14   \n",
                        "\n",
                        "   DiscountedSimilarity  \n",
                        "0                  0.21  \n",
                        "1                  0.14  \n",
                        "2                  0.14  \n",
                        "3                  0.14  \n",
                        "4                  0.14  \n",
                        "Comparison results saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Comparing top users lists...\")\n",
                "comparison_results = []\n",
                "overlap_pairs = []\n",
                "\n",
                "all_target_users = set(df_top_similar_users['TargetUser']).union(set(df_top_ds_users['TargetUser']))\n",
                "\n",
                "for target_user in all_target_users:\n",
                "    top_users_std = set(df_top_similar_users[df_top_similar_users['TargetUser'] == target_user]['OtherUser'])\n",
                "    top_users_ds = set(df_top_ds_users[df_top_ds_users['TargetUser'] == target_user]['OtherUser'])\n",
                "    \n",
                "    overlap = top_users_std.intersection(top_users_ds)\n",
                "    overlap_count = len(overlap)\n",
                "\n",
                "    for other_user in overlap:\n",
                "        overlap_pairs.append({\n",
                "            'TargetUser': target_user,\n",
                "            'OtherUser': other_user\n",
                "        })\n",
                "\n",
                "    comparison_results.append({\n",
                "        'TargetUser': target_user,\n",
                "        'StandardCount': len(top_users_std),\n",
                "        'DSCount': len(top_users_ds),\n",
                "        'OverlapCount': overlap_count,\n",
                "        'OverlapPercentage': round(overlap_count / len(top_users_std) * 100, 2) if len(top_users_std) > 0 else 0\n",
                "    })\n",
                "\n",
                "df_comparison = pd.DataFrame(comparison_results)\n",
                "print(f\"Average Overlap Percentage: {df_comparison['OverlapPercentage'].mean():.2f}%\")\n",
                "print(df_comparison.head())\n",
                "\n",
                "df_overlap_keys = pd.DataFrame(overlap_pairs)\n",
                "\n",
                "print(f\"Total overlapping (TargetUser, OtherUser) pairs: {len(df_overlap_keys)}\")\n",
                "print(df_overlap_keys.head())\n",
                "\n",
                "df_overlap_details = pd.merge(\n",
                "    df_overlap_keys,\n",
                "    df_ds,  \n",
                "    on=['TargetUser', 'OtherUser'],\n",
                "    how='left'\n",
                ")\n",
                "\n",
                "overlap_output_file = '../../results/3_2_1_1_7_overlap_users.csv'\n",
                "df_overlap_details.to_csv(overlap_output_file, index=False)\n",
                "print(f\"Intersection users with details saved successfully to {overlap_output_file}.\")\n",
                "print(df_overlap_details.head())\n",
                "\n",
                "df_comparison.to_csv('../../results/3_2_1_1_7_comparison_results.csv', index=False)\n",
                "print(\"Comparison results saved successfully.\") "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.1.8\n",
                "\n",
                "This section merges the rating predictions generated using standard cosine similarity and Discounted Similarity (DS) for the same (TargetUser, Item) pairs. \n",
                " \n",
                "It computes the difference between the two prediction values and reports basic statistics.  \n",
                "\n",
                "The comparison results are saved to:  \n",
                "`3_2_1_1_8_pred_comparison.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing rating predictions...\n",
                        "Compared 361 common predictions.\n",
                        "Average Difference: 0.1080\n",
                        "       TargetUser        Item  PredictedRating_Std  PredictedRating_DS  \\\n",
                        "0  A1ER5AYS3FQ9O3  B004Z74P0K                  2.0                 2.0   \n",
                        "1  A1ER5AYS3FQ9O3  B00BXJZ3KY                  4.5                 5.0   \n",
                        "2  A1ER5AYS3FQ9O3  B0072ZQGIG                  4.0                 4.0   \n",
                        "3  A1ER5AYS3FQ9O3  B000CDWNSW                  5.0                 5.0   \n",
                        "4  A1ER5AYS3FQ9O3  B001QFZMD8                  5.0                 5.0   \n",
                        "\n",
                        "   Difference  \n",
                        "0         0.0  \n",
                        "1        -0.5  \n",
                        "2         0.0  \n",
                        "3         0.0  \n",
                        "4         0.0  \n",
                        "Predictions comparison saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Comparing rating predictions...\")\n",
                "\n",
                "df_pred_comparison = pd.merge(\n",
                "    df_predictions[['TargetUser', 'Item', 'PredictedRating']],\n",
                "    df_predictions_ds[['TargetUser', 'Item', 'PredictedRating']],\n",
                "    on=['TargetUser', 'Item'],\n",
                "    suffixes=('_Std', '_DS'),\n",
                "    how='inner'\n",
                ")\n",
                "\n",
                "df_pred_comparison['Difference'] = df_pred_comparison['PredictedRating_Std'] - df_pred_comparison['PredictedRating_DS']\n",
                "\n",
                "print(f\"Compared {len(df_pred_comparison)} common predictions.\")\n",
                "print(f\"Average Difference: {df_pred_comparison['Difference'].abs().mean():.4f}\")\n",
                "print(df_pred_comparison.head())\n",
                "\n",
                "df_pred_comparison.to_csv('../../results/3_2_1_1_8_pred_comparison.csv', index=False)\n",
                "print(\"Predictions comparison saved successfully.\") "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.1.9\n",
                "\n",
                "This section counts how many items each user has rated and stores the result in `df_user_counts`.  \n",
                "\n",
                "It then filters all user pairs with cosine similarity equal to 1.0 from `df_results_filtered`, merges their total rated item counts for both target and other users, and saves the final table to:  \n",
                "`3_2_1_1_9_perfect_similarity_pairs.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "User rating counts (first 5):\n",
                        "           UserID  NumRatedItems\n",
                        "0  A1N070NS9CJQ2I              2\n",
                        "1  A3P0KRKOBQK1KN              1\n",
                        "2  A192HO2ICJ75VU              1\n",
                        "3  A2T278FKFL3BLT              1\n",
                        "4  A2ZUXVTW8RXBXW              1\n",
                        "Finding pairs with perfect cosine similarity (1.0)...\n",
                        "Found 53 user pairs with Similarity = 1.0.\n",
                        "         TargetUser       OtherUser  Similarity  CommonItems\n",
                        "52   A1ER5AYS3FQ9O3  A2JCJJNY43QQIV         1.0            3\n",
                        "55   A1ER5AYS3FQ9O3   AM9APPMIE1BHZ         1.0            3\n",
                        "87   A1ER5AYS3FQ9O3  A37PV5GMP2ILJC         1.0            2\n",
                        "154  A1ER5AYS3FQ9O3  A1S3FOP19D8W1X         1.0            2\n",
                        "212  A1ER5AYS3FQ9O3  A3CW0ZLUO5X2B1         1.0            2\n",
                        "Perfect similarity pairs with total rated items:\n",
                        "       TargetUser       OtherUser  Similarity  CommonItems  \\\n",
                        "0  A1ER5AYS3FQ9O3  A2JCJJNY43QQIV         1.0            3   \n",
                        "1  A1ER5AYS3FQ9O3   AM9APPMIE1BHZ         1.0            3   \n",
                        "2  A1ER5AYS3FQ9O3  A37PV5GMP2ILJC         1.0            2   \n",
                        "3  A1ER5AYS3FQ9O3  A1S3FOP19D8W1X         1.0            2   \n",
                        "4  A1ER5AYS3FQ9O3  A3CW0ZLUO5X2B1         1.0            2   \n",
                        "\n",
                        "   TargetUserTotalItems  OtherUserTotalItems  \n",
                        "0                    44                  112  \n",
                        "1                    44                   50  \n",
                        "2                    44                   44  \n",
                        "3                    44                   46  \n",
                        "4                    44                  345  \n",
                        "Perfect similarity pairs saved successfully to ../../results/3_2_1_1_9_perfect_similarity_pairs.csv.\n"
                    ]
                }
            ],
            "source": [
                "user_rating_counts = {\n",
                "    user: len(items) for user, items in user_item_ratings.items()\n",
                "}\n",
                "\n",
                "df_user_counts = pd.DataFrame(\n",
                "    [{'UserID': u, 'NumRatedItems': c} for u, c in user_rating_counts.items()]\n",
                ")\n",
                "\n",
                "print(\"User rating counts (first 5):\")\n",
                "print(df_user_counts.head())\n",
                "\n",
                "print(\"Finding pairs with perfect cosine similarity (1.0)...\")\n",
                "\n",
                "df_perfect = df_results_filtered[df_results_filtered['Similarity'] == 1.0].copy()\n",
                "\n",
                "print(f\"Found {len(df_perfect)} user pairs with Similarity = 1.0.\")\n",
                "print(df_perfect.head())\n",
                "\n",
                "df_perfect = df_perfect.merge(\n",
                "    df_user_counts.rename(columns={\n",
                "        'UserID': 'TargetUser',\n",
                "        'NumRatedItems': 'TargetUserTotalItems'\n",
                "    }),\n",
                "    on='TargetUser',\n",
                "    how='left'\n",
                ")\n",
                "\n",
                "df_perfect = df_perfect.merge(\n",
                "    df_user_counts.rename(columns={\n",
                "        'UserID': 'OtherUser',\n",
                "        'NumRatedItems': 'OtherUserTotalItems'\n",
                "    }),\n",
                "    on='OtherUser',\n",
                "    how='left'\n",
                ")\n",
                "\n",
                "print(\"Perfect similarity pairs with total rated items:\")\n",
                "print(df_perfect.head())\n",
                "\n",
                "perfect_output_file = '../../results/3_2_1_1_9_perfect_similarity_pairs.csv'\n",
                "df_perfect.to_csv(perfect_output_file, index=False)\n",
                "print(f\"Perfect similarity pairs saved successfully to {perfect_output_file}.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Case Study 2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.2.1\n",
                "\n",
                "This section defines helper functions to:\n",
                "- Compute the mean rating for each user (`compute_user_means`)\n",
                "- Compute rating deviations from the user mean (`compute_rating_deviations`)\n",
                "- Calculate mean-centered cosine similarity between two users using these deviations (`calculate_mean_centered_cosine_similarity`)\n",
                "\n",
                "It then uses the co-rated user pairs in `df_co_users` to compute mean-centered cosine similarities, stores the results in a DataFrame, and saves:\n",
                "- All results to: `3_2_1_2_1_user_similarities_mean_centered.csv`\n",
                "- A filtered version with `CommonItems > 1` to: `3_2_1_2_1_user_similarities_mean_centered_filtered.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_user_means(user_ratings):\n",
                "    user_means = {}\n",
                "\n",
                "    for user, items in user_ratings.items():\n",
                "        if len(items) > 0:\n",
                "            user_means[user] = sum(items.values()) / len(items)\n",
                "        else:\n",
                "            user_means[user] = 0.0\n",
                "\n",
                "    return user_means"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_rating_deviations(user_ratings, user_means):\n",
                "    deviations = {}\n",
                "\n",
                "    for user, items in user_ratings.items():\n",
                "        mean = user_means[user]\n",
                "        deviations[user] = {\n",
                "            item: (rating - mean) for item, rating in items.items()\n",
                "        }\n",
                "\n",
                "    return deviations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_mean_centered_cosine_similarity(user1, user2, deviations):\n",
                "    u1_items = deviations.get(user1, {})\n",
                "    u2_items = deviations.get(user2, {})\n",
                "\n",
                "    # Common rated items\n",
                "    common_items = set(u1_items.keys()) & set(u2_items.keys())\n",
                "\n",
                "    if not common_items:\n",
                "        return 0.0, 0\n",
                "\n",
                "    dot = 0.0\n",
                "    norm1 = 0.0\n",
                "    norm2 = 0.0\n",
                "\n",
                "    for item in common_items:\n",
                "        d1 = u1_items[item]\n",
                "        d2 = u2_items[item]\n",
                "\n",
                "        dot += d1 * d2\n",
                "        norm1 += d1 ** 2\n",
                "        norm2 += d2 ** 2\n",
                "\n",
                "    norm1 = norm1 ** 0.5\n",
                "    norm2 = norm2 ** 0.5\n",
                "\n",
                "    if norm1 == 0 or norm2 == 0:\n",
                "        return 0.0, len(common_items)\n",
                "\n",
                "    similarity = dot / (norm1 * norm2)\n",
                "\n",
                "    return similarity, len(common_items)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating mean-centered cosine similarities...\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Mean-centered similarity calculation complete.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Calculating mean-centered cosine similarities...\")\n",
                "mc_similarities = []\n",
                "\n",
                "user_means = compute_user_means(user_item_ratings)\n",
                "deviations = compute_rating_deviations(user_item_ratings, user_means)\n",
                "\n",
                "\n",
                "for index, row in df_co_users.iterrows():\n",
                "    target_user = row['TargetUser']\n",
                "    other_user = row['OtherUser']\n",
                "    \n",
                "    sim, num_common = calculate_mean_centered_cosine_similarity(\n",
                "        target_user, \n",
                "        other_user, \n",
                "        deviations\n",
                "    )\n",
                "    \n",
                "    mc_similarities.append({\n",
                "        'TargetUser': target_user,\n",
                "        'OtherUser': other_user,\n",
                "        'MeanCenteredSimilarity': round(sim, 2),\n",
                "        'CommonItems': num_common\n",
                "    })\n",
                "\n",
                "print(\"Mean-centered similarity calculation complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saving mean-centered similarity results...\n",
                        "Mean-centered similarities saved successfully.\n",
                        "       TargetUser       OtherUser  MeanCenteredSimilarity  CommonItems\n",
                        "0  A1ER5AYS3FQ9O3   AAP7PPBU72QFM                     0.0            1\n",
                        "1  A1ER5AYS3FQ9O3   AIMPBO9K5SQ5X                    -1.0            1\n",
                        "2  A1ER5AYS3FQ9O3  A2QCVDCCZ3ABAC                     0.0            1\n",
                        "3  A1ER5AYS3FQ9O3  A1C0Y8AFKTIRWY                     0.0            1\n",
                        "4  A1ER5AYS3FQ9O3  A3M96C2MSACALP                     0.0            1\n",
                        "         TargetUser       OtherUser  MeanCenteredSimilarity  CommonItems\n",
                        "52   A1ER5AYS3FQ9O3  A2JCJJNY43QQIV                    1.00            3\n",
                        "55   A1ER5AYS3FQ9O3   AM9APPMIE1BHZ                    1.00            3\n",
                        "87   A1ER5AYS3FQ9O3  A37PV5GMP2ILJC                   -1.00            2\n",
                        "93   A1ER5AYS3FQ9O3  A259HHYBP6ZNJ3                    0.04            2\n",
                        "124  A1ER5AYS3FQ9O3   A680RUE1FDO8B                    0.38            2\n",
                        "Filtered mean-centered similarities saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Saving mean-centered similarity results...\")\n",
                "df_mc_results = pd.DataFrame(mc_similarities)\n",
                "df_mc_results.to_csv('../../results/3_2_1_2_1_user_similarities_mean_centered.csv', index=False)\n",
                "print(\"Mean-centered similarities saved successfully.\")\n",
                "print(df_mc_results.head())\n",
                "\n",
                "df_mc_results_filtered = df_mc_results[df_mc_results['CommonItems'] > 1]\n",
                "print(df_mc_results_filtered.head())\n",
                "\n",
                "df_mc_results_filtered.to_csv('../../results/3_2_1_2_1_user_similarities_mean_centered_filtered.csv', index=False)\n",
                "print(\"Filtered mean-centered similarities saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.2.2\n",
                "\n",
                "This section selects the top 20% most similar users per target user using mean-centered cosine similarity values.  \n",
                "\n",
                "The selected user pairs are saved to:  \n",
                "`3_2_1_2_2_top_similar_users_mean_centered.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Identifying top 20% similar users based on mean-centered similarity...\n",
                        "Identified 21 top similar user pairs (mean-centered).\n",
                        "Saving top 20% mean-centered similar users to ../../results/3_2_1_2_2_top_similar_users_mean_centered.csv...\n",
                        "Top 20% mean-centered users saved successfully.\n",
                        "          TargetUser       OtherUser  MeanCenteredSimilarity  CommonItems\n",
                        "52    A1ER5AYS3FQ9O3  A2JCJJNY43QQIV                     1.0            3\n",
                        "6511  A1ER5AYS3FQ9O3  A3LY8LCT1QE8I1                     1.0            2\n",
                        "378   A1ER5AYS3FQ9O3  A19W47CXJJP1MI                     1.0            2\n",
                        "1063  A1ER5AYS3FQ9O3  A2DPSV4CTHV3YA                     1.0            2\n",
                        "691   A1ER5AYS3FQ9O3  A35X2JJI49OBZP                     1.0            2\n"
                    ]
                }
            ],
            "source": [
                "print(\"Identifying top 20% similar users based on mean-centered similarity...\")\n",
                "\n",
                "df_top_mc_users = get_top_n_similar_users(df_mc_results_filtered, n_percentage=0.20, similarity_col='MeanCenteredSimilarity')\n",
                "\n",
                "print(f\"Identified {len(df_top_mc_users)} top similar user pairs (mean-centered).\")\n",
                "\n",
                "top_mc_output_file = '../../results/3_2_1_2_2_top_similar_users_mean_centered.csv'\n",
                "print(f\"Saving top 20% mean-centered similar users to {top_mc_output_file}...\")\n",
                "\n",
                "df_top_mc_users.to_csv(top_mc_output_file, index=False)\n",
                "\n",
                "print(\"Top 20% mean-centered users saved successfully.\")\n",
                "print(df_top_mc_users.head())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.2.3\n",
                "\n",
                "This section predicts ratings for unrated items by applying the weighted mean-centered cosine similarity from the selected top similar users.\n",
                "  \n",
                "The resulting predictions are saved to:  \n",
                "`3_2_1_2_3_predictions_mean_centered.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting unknown ratings using mean-centered similarity...\n",
                        "Generated 1803 predictions (mean-centered).\n",
                        "Saving mean-centered predictions to ../../results/3_2_1_2_3_predictions_mean_centered.csv...\n",
                        "Mean-centered predictions saved successfully.\n",
                        "       TargetUser        Item  PredictedRating          SimilarityType\n",
                        "0  A1ER5AYS3FQ9O3  B0019FHM9M              1.0  MeanCenteredSimilarity\n",
                        "1  A1ER5AYS3FQ9O3  B00Q543KL6              5.0  MeanCenteredSimilarity\n",
                        "2  A1ER5AYS3FQ9O3  B001UQ6F4S              5.0  MeanCenteredSimilarity\n",
                        "3  A1ER5AYS3FQ9O3  B00DQIST6A              4.0  MeanCenteredSimilarity\n",
                        "4  A1ER5AYS3FQ9O3  B004W7PHVO              4.0  MeanCenteredSimilarity\n"
                    ]
                }
            ],
            "source": [
                "print(\"Predicting unknown ratings using mean-centered similarity...\")\n",
                "\n",
                "df_predictions_mc = predict_ratings(df_top_mc_users, user_item_ratings, sim_col='MeanCenteredSimilarity')\n",
                "\n",
                "print(f\"Generated {len(df_predictions_mc)} predictions (mean-centered).\")\n",
                "\n",
                "predictions_mc_file = '../../results/3_2_1_2_3_predictions_mean_centered.csv'\n",
                "print(f\"Saving mean-centered predictions to {predictions_mc_file}...\")\n",
                "\n",
                "df_predictions_mc.to_csv(predictions_mc_file, index=False)\n",
                "\n",
                "print(\"Mean-centered predictions saved successfully.\")\n",
                "print(df_predictions_mc.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.2.4\n",
                "\n",
                "This section applies the Discounted Similarity (DS) method to mean-centered cosine similarity results by incorporating a discount factor based on common rated items. \n",
                " \n",
                "The results are saved to:  \n",
                "`3_2_1_2_4_discounted_similarity_mean_centered.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating Discounted Mean-Centered Similarity...\n",
                        "Mean-centered DS calculation complete.\n",
                        "       TargetUser       OtherUser  MeanCenteredSimilarity  CommonItems  \\\n",
                        "0  A1ER5AYS3FQ9O3  A2JCJJNY43QQIV                    1.00            3   \n",
                        "1  A1ER5AYS3FQ9O3   AM9APPMIE1BHZ                    1.00            3   \n",
                        "2  A1ER5AYS3FQ9O3  A37PV5GMP2ILJC                   -1.00            2   \n",
                        "3  A1ER5AYS3FQ9O3  A259HHYBP6ZNJ3                    0.04            2   \n",
                        "4  A1ER5AYS3FQ9O3   A680RUE1FDO8B                    0.38            2   \n",
                        "\n",
                        "   DiscountFactor  DiscountedSimilarity  \n",
                        "0            0.21                  0.21  \n",
                        "1            0.21                  0.21  \n",
                        "2            0.14                 -0.14  \n",
                        "3            0.14                  0.01  \n",
                        "4            0.14                  0.05  \n",
                        "Saving Mean-Centered Discounted Similarity to ../../results/3_2_1_2_4_discounted_similarity_mean_centered.csv...\n",
                        "Mean-Centered Discounted Similarity saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Calculating Discounted Mean-Centered Similarity...\")\n",
                "\n",
                "df_ds_mc = calculate_discounted_similarity(df_mc_results_filtered,user_item_ratings,beta_pct=0.3, sim_col='MeanCenteredSimilarity')\n",
                "\n",
                "print(\"Mean-centered DS calculation complete.\")\n",
                "print(df_ds_mc.head())\n",
                "\n",
                "ds_mc_output_file = '../../results/3_2_1_2_4_discounted_similarity_mean_centered.csv'\n",
                "print(f\"Saving Mean-Centered Discounted Similarity to {ds_mc_output_file}...\")\n",
                "\n",
                "df_ds_mc.to_csv(ds_mc_output_file, index=False)\n",
                "\n",
                "print(\"Mean-Centered Discounted Similarity saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.2.5\n",
                "\n",
                "This section selects the top 20% most similar users per target user using Discounted Similarity values derived from mean-centered cosine similarity. \n",
                " \n",
                "The resulting user pairs are saved to:  \n",
                "`3_2_1_2_5_top_similar_users_mean_centered_ds.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Identifying top 20% similar users based on Mean-Centered DS...\n",
                        "Identified 21 top similar user pairs (Mean-Centered DS).\n",
                        "Saving top 20% Mean-Centered DS users to ../../results/3_2_1_2_5_top_similar_users_mean_centered_ds.csv...\n",
                        "Top Mean-Centered DS users saved successfully.\n",
                        "        TargetUser       OtherUser  MeanCenteredSimilarity  CommonItems  \\\n",
                        "0   A1ER5AYS3FQ9O3  A2JCJJNY43QQIV                    1.00            3   \n",
                        "1   A1ER5AYS3FQ9O3   AM9APPMIE1BHZ                    1.00            3   \n",
                        "71  A1ER5AYS3FQ9O3  A2CVXUY1EYQGGA                    0.98            3   \n",
                        "54  A1ER5AYS3FQ9O3   AWPN47SSWK1JV                    0.96            3   \n",
                        "15  A1ER5AYS3FQ9O3   ASY25YMTIC2A9                    0.74            3   \n",
                        "\n",
                        "    DiscountFactor  DiscountedSimilarity  \n",
                        "0             0.21                  0.21  \n",
                        "1             0.21                  0.21  \n",
                        "71            0.21                  0.21  \n",
                        "54            0.21                  0.21  \n",
                        "15            0.21                  0.16  \n"
                    ]
                }
            ],
            "source": [
                "print(\"Identifying top 20% similar users based on Mean-Centered DS...\")\n",
                "\n",
                "df_top_ds_mc_users = get_top_n_similar_users(df_ds_mc,n_percentage=0.20,similarity_col='DiscountedSimilarity')\n",
                "\n",
                "print(f\"Identified {len(df_top_ds_mc_users)} top similar user pairs (Mean-Centered DS).\")\n",
                "\n",
                "top_ds_mc_output_file = '../../results/3_2_1_2_5_top_similar_users_mean_centered_ds.csv'\n",
                "print(f\"Saving top 20% Mean-Centered DS users to {top_ds_mc_output_file}...\")\n",
                "\n",
                "df_top_ds_mc_users.to_csv(top_ds_mc_output_file, index=False)\n",
                "\n",
                "print(\"Top Mean-Centered DS users saved successfully.\")\n",
                "print(df_top_ds_mc_users.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.2.6\n",
                "\n",
                "This section predicts ratings for unrated items using the top similar users identified by Mean-Centered Discounted Similarity. \n",
                " \n",
                "The generated predictions are saved to:  \n",
                "`3_2_1_2_6_predictions_mean_centered_ds.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting unknown ratings using Discounted Mean-Centered Similarity...\n",
                        "Generated 1766 predictions (Mean-Centered DS).\n",
                        "Saving Mean-Centered DS-based predictions to ../../results/3_2_1_2_6_predictions_mean_centered_ds.csv...\n",
                        "Mean-Centered DS predictions saved successfully.\n",
                        "       TargetUser        Item  PredictedRating        SimilarityType\n",
                        "0  A1ER5AYS3FQ9O3  B00MCVPIJI              3.0  DiscountedSimilarity\n",
                        "1  A1ER5AYS3FQ9O3  B005ZG0IME              2.0  DiscountedSimilarity\n",
                        "2  A1ER5AYS3FQ9O3  B01FFRD1NU              5.0  DiscountedSimilarity\n",
                        "3  A1ER5AYS3FQ9O3  B0019FHM9M              1.0  DiscountedSimilarity\n",
                        "4  A1ER5AYS3FQ9O3  B001UQ6F4S              5.0  DiscountedSimilarity\n"
                    ]
                }
            ],
            "source": [
                "print(\"Predicting unknown ratings using Discounted Mean-Centered Similarity...\")\n",
                "\n",
                "df_predictions_ds_mc = predict_ratings(df_top_ds_mc_users,user_item_ratings,sim_col='DiscountedSimilarity')\n",
                "\n",
                "print(f\"Generated {len(df_predictions_ds_mc)} predictions (Mean-Centered DS).\")\n",
                "\n",
                "predictions_ds_mc_file = '../../results/3_2_1_2_6_predictions_mean_centered_ds.csv'\n",
                "print(f\"Saving Mean-Centered DS-based predictions to {predictions_ds_mc_file}...\")\n",
                "\n",
                "df_predictions_ds_mc.to_csv(predictions_ds_mc_file, index=False)\n",
                "\n",
                "print(\"Mean-Centered DS predictions saved successfully.\")\n",
                "print(df_predictions_ds_mc.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.2.7\n",
                "\n",
                "This section compares the top similar users selected using Mean-Centered Cosine Similarity versus Mean-Centered Discounted Similarity (DS).  \n",
                "\n",
                "It calculates overlap statistics for each target user and saves:\n",
                "- Detailed overlapping user pairs to:  \n",
                "  `3_2_1_2_7_overlap_users_mean_centered.csv`  \n",
                "\n",
                "- Summary comparison statistics per target user to:  \n",
                "  `3_2_1_2_7_comparison_results_mean_centered.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing top users lists (Mean-Centered)...\n",
                        "Average Overlap Percentage (Mean-Centered): 66.67%\n",
                        "       TargetUser  MCCount  MC_DSCount  OverlapCount  OverlapPercentage\n",
                        "0  A1ER5AYS3FQ9O3       21          21            14              66.67\n",
                        "Total overlapping (TargetUser, OtherUser) pairs (Mean-Centered): 14\n",
                        "       TargetUser       OtherUser\n",
                        "0  A1ER5AYS3FQ9O3  A18DQ9ZJOPUWCO\n",
                        "1  A1ER5AYS3FQ9O3  A11B61QBGHLQDN\n",
                        "2  A1ER5AYS3FQ9O3  A35X2JJI49OBZP\n",
                        "3  A1ER5AYS3FQ9O3  A2JCJJNY43QQIV\n",
                        "4  A1ER5AYS3FQ9O3  A3AUL23GMCOP2A\n",
                        "Intersection users (Mean-Centered) with details saved successfully to ../../results/3_2_1_2_7_overlap_users_mean_centered.csv.\n",
                        "       TargetUser       OtherUser  MeanCenteredSimilarity  CommonItems  \\\n",
                        "0  A1ER5AYS3FQ9O3  A18DQ9ZJOPUWCO                     1.0            2   \n",
                        "1  A1ER5AYS3FQ9O3  A11B61QBGHLQDN                     1.0            2   \n",
                        "2  A1ER5AYS3FQ9O3  A35X2JJI49OBZP                     1.0            2   \n",
                        "3  A1ER5AYS3FQ9O3  A2JCJJNY43QQIV                     1.0            3   \n",
                        "4  A1ER5AYS3FQ9O3  A3AUL23GMCOP2A                     1.0            2   \n",
                        "\n",
                        "   DiscountFactor  DiscountedSimilarity  \n",
                        "0            0.14                  0.14  \n",
                        "1            0.14                  0.14  \n",
                        "2            0.14                  0.14  \n",
                        "3            0.21                  0.21  \n",
                        "4            0.14                  0.14  \n",
                        "Mean-Centered comparison results saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Comparing top users lists (Mean-Centered)...\")\n",
                "\n",
                "mc_comparison_results = []\n",
                "mc_overlap_pairs = []\n",
                "\n",
                "all_target_users_mc = set(df_top_mc_users['TargetUser']).union(\n",
                "    set(df_top_ds_mc_users['TargetUser'])\n",
                ")\n",
                "\n",
                "for target_user in all_target_users_mc:\n",
                "    top_users_mc = set(\n",
                "        df_top_mc_users[df_top_mc_users['TargetUser'] == target_user]['OtherUser']\n",
                "    )\n",
                "    top_users_ds_mc = set(\n",
                "        df_top_ds_mc_users[df_top_ds_mc_users['TargetUser'] == target_user]['OtherUser']\n",
                "    )\n",
                "    \n",
                "    overlap = top_users_mc.intersection(top_users_ds_mc)\n",
                "    overlap_count = len(overlap)\n",
                "\n",
                "    for other_user in overlap:\n",
                "        mc_overlap_pairs.append({\n",
                "            'TargetUser': target_user,\n",
                "            'OtherUser': other_user\n",
                "        })\n",
                "\n",
                "    mc_comparison_results.append({\n",
                "        'TargetUser': target_user,\n",
                "        'MCCount': len(top_users_mc),\n",
                "        'MC_DSCount': len(top_users_ds_mc),\n",
                "        'OverlapCount': overlap_count,\n",
                "        'OverlapPercentage': round(overlap_count / len(top_users_mc) * 100, 2) \n",
                "                            if len(top_users_mc) > 0 else 0\n",
                "    })\n",
                "\n",
                "df_mc_comparison = pd.DataFrame(mc_comparison_results)\n",
                "print(f\"Average Overlap Percentage (Mean-Centered): {df_mc_comparison['OverlapPercentage'].mean():.2f}%\")\n",
                "print(df_mc_comparison.head())\n",
                "\n",
                "df_mc_overlap_keys = pd.DataFrame(mc_overlap_pairs)\n",
                "\n",
                "print(f\"Total overlapping (TargetUser, OtherUser) pairs (Mean-Centered): {len(df_mc_overlap_keys)}\")\n",
                "print(df_mc_overlap_keys.head())\n",
                "\n",
                "df_mc_overlap_details = pd.merge(\n",
                "    df_mc_overlap_keys,\n",
                "    df_ds_mc,   \n",
                "    on=['TargetUser', 'OtherUser'],\n",
                "    how='left'\n",
                ")\n",
                "\n",
                "overlap_mc_output_file = '../../results/3_2_1_2_7_overlap_users_mean_centered.csv'\n",
                "df_mc_overlap_details.to_csv(overlap_mc_output_file, index=False)\n",
                "print(f\"Intersection users (Mean-Centered) with details saved successfully to {overlap_mc_output_file}.\")\n",
                "print(df_mc_overlap_details.head())\n",
                "\n",
                "comparison_mc_output_file = '../../results/3_2_1_2_7_comparison_results_mean_centered.csv'\n",
                "df_mc_comparison.to_csv(comparison_mc_output_file, index=False)\n",
                "print(\"Mean-Centered comparison results saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.2.8\n",
                "\n",
                "This section compares the predicted ratings generated using Mean-Centered Cosine Similarity and Mean-Centered Discounted Similarity (DS) for identical (TargetUser, Item) pairs.  \n",
                "\n",
                "It computes the difference between the two predictions and saves the comparison results to:  \n",
                "`3_2_1_2_8_pred_comparison_mean_centered.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing rating predictions (Mean-Centered)...\n",
                        "Compared 1242 common predictions (Mean-Centered).\n",
                        "Average Difference: 0.0532\n",
                        "       TargetUser        Item  PredictedRating_MC  PredictedRating_MC_DS  \\\n",
                        "0  A1ER5AYS3FQ9O3  B0019FHM9M                 1.0                    1.0   \n",
                        "1  A1ER5AYS3FQ9O3  B001UQ6F4S                 5.0                    5.0   \n",
                        "2  A1ER5AYS3FQ9O3  B00DQIST6A                 4.0                    4.0   \n",
                        "3  A1ER5AYS3FQ9O3  B004W7PHVO                 4.0                    4.0   \n",
                        "4  A1ER5AYS3FQ9O3  B004XIOJ7A                 5.0                    5.0   \n",
                        "\n",
                        "   Difference  \n",
                        "0         0.0  \n",
                        "1         0.0  \n",
                        "2         0.0  \n",
                        "3         0.0  \n",
                        "4         0.0  \n",
                        "Mean-Centered predictions comparison saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Comparing rating predictions (Mean-Centered)...\")\n",
                "\n",
                "df_pred_comparison_mc = pd.merge(\n",
                "    df_predictions_mc[['TargetUser', 'Item', 'PredictedRating']],\n",
                "    df_predictions_ds_mc[['TargetUser', 'Item', 'PredictedRating']],\n",
                "    on=['TargetUser', 'Item'],\n",
                "    suffixes=('_MC', '_MC_DS'),\n",
                "    how='inner'\n",
                ")\n",
                "\n",
                "df_pred_comparison_mc['Difference'] = \\\n",
                "    df_pred_comparison_mc['PredictedRating_MC'] - df_pred_comparison_mc['PredictedRating_MC_DS']\n",
                "\n",
                "print(f\"Compared {len(df_pred_comparison_mc)} common predictions (Mean-Centered).\")\n",
                "print(f\"Average Difference: {df_pred_comparison_mc['Difference'].abs().mean():.4f}\")\n",
                "print(df_pred_comparison_mc.head())\n",
                "\n",
                "pred_comp_mc_output = '../../results/3_2_1_2_8_pred_comparison_mean_centered.csv'\n",
                "df_pred_comparison_mc.to_csv(pred_comp_mc_output, index=False)\n",
                "\n",
                "print(\"Mean-Centered predictions comparison saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.2.9\n",
                "\n",
                "This section finds user pairs where the raw cosine similarity is highly positive (≥ 1.0) while the mean-centered similarity equals -1.0. \n",
                " \n",
                "It merges raw and mean-centered similarity results, filters such “flipped” pairs, and saves them to:  \n",
                "`3_2_1_2_9_raw_high_mc_minus1_pairs.csv`  \n",
                "\n",
                "It then builds item-level details for these pairs, including ratings, user means, and deviations for each common item, and saves them to:  \n",
                "`3_2_1_2_9_raw_high_mc_minus1_pairs_items.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Finding user pairs where raw cosine is highly +ve but mean-centered similarity is -1.0...\n",
                        "Found 15 user pairs with raw cosine ≥ 1 and mean-centered = -1.0.\n",
                        "        TargetUser       OtherUser  Similarity  CommonItems  \\\n",
                        "2   A1ER5AYS3FQ9O3  A37PV5GMP2ILJC         1.0            2   \n",
                        "22  A1ER5AYS3FQ9O3  A10ZBR6O8S8OCY         1.0            2   \n",
                        "23  A1ER5AYS3FQ9O3  A20DDH4NT6Q1E8         1.0            2   \n",
                        "27  A1ER5AYS3FQ9O3  A1VLVWTLV3LVHR         1.0            2   \n",
                        "37  A1ER5AYS3FQ9O3  A2NICGGIGIFU22         1.0            2   \n",
                        "\n",
                        "    MeanCenteredSimilarity  \n",
                        "2                     -1.0  \n",
                        "22                    -1.0  \n",
                        "23                    -1.0  \n",
                        "27                    -1.0  \n",
                        "37                    -1.0  \n",
                        "Flipped similarity pairs saved successfully to ../../results/3_2_1_2_9_raw_high_mc_minus1_pairs.csv.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Finding user pairs where raw cosine is highly +ve but mean-centered similarity is -1.0...\")\n",
                "\n",
                "HIGH_SIM_THRESHOLD = 1  \n",
                "\n",
                "df_merged_sims = pd.merge(\n",
                "    df_results_filtered[['TargetUser', 'OtherUser', 'Similarity', 'CommonItems']],\n",
                "    df_mc_results_filtered[['TargetUser', 'OtherUser', 'MeanCenteredSimilarity']],\n",
                "    on=['TargetUser', 'OtherUser'],\n",
                "    how='inner'\n",
                ")\n",
                "\n",
                "df_flip_pairs = df_merged_sims[\n",
                "    (df_merged_sims['Similarity'] >= HIGH_SIM_THRESHOLD) &\n",
                "    (df_merged_sims['MeanCenteredSimilarity'] == -1.0)\n",
                "].copy()\n",
                "\n",
                "print(f\"Found {len(df_flip_pairs)} user pairs with raw cosine ≥ {HIGH_SIM_THRESHOLD} and mean-centered = -1.0.\")\n",
                "print(df_flip_pairs.head())\n",
                "\n",
                "flip_output_file = '../../results/3_2_1_2_9_raw_high_mc_minus1_pairs.csv'\n",
                "df_flip_pairs.to_csv(flip_output_file, index=False)\n",
                "print(f\"Flipped similarity pairs saved successfully to {flip_output_file}.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building item-level details for flipped pairs (means and deviations)...\n",
                        "Built item-level details for 30 (user, item) rows.\n",
                        "       TargetUser       OtherUser      ItemID  RawCosineSimilarity  \\\n",
                        "0  A1ER5AYS3FQ9O3  A37PV5GMP2ILJC  B000RHZJN4                  1.0   \n",
                        "1  A1ER5AYS3FQ9O3  A37PV5GMP2ILJC  B000V1MLBE                  1.0   \n",
                        "2  A1ER5AYS3FQ9O3  A10ZBR6O8S8OCY  B00A6HYP1W                  1.0   \n",
                        "3  A1ER5AYS3FQ9O3  A10ZBR6O8S8OCY  B004HKJTT2                  1.0   \n",
                        "4  A1ER5AYS3FQ9O3  A20DDH4NT6Q1E8  B00E5JUEF8                  1.0   \n",
                        "\n",
                        "   MeanCenteredSimilarity  CommonItemsCount  TargetRating  OtherRating  \\\n",
                        "0                    -1.0                 2           5.0          4.0   \n",
                        "1                    -1.0                 2           5.0          4.0   \n",
                        "2                    -1.0                 2           4.0          5.0   \n",
                        "3                    -1.0                 2           4.0          5.0   \n",
                        "4                    -1.0                 2           5.0          4.0   \n",
                        "\n",
                        "   TargetUserMean  OtherUserMean  TargetDeviation  OtherDeviation  \n",
                        "0        4.295455       4.113636         0.704545       -0.113636  \n",
                        "1        4.295455       4.113636         0.704545       -0.113636  \n",
                        "2        4.295455       4.516949        -0.295455        0.483051  \n",
                        "3        4.295455       4.516949        -0.295455        0.483051  \n",
                        "4        4.295455       4.481132         0.704545       -0.481132  \n",
                        "Item-level flipped similarity details saved successfully to ../../results/3_2_1_2_9_raw_high_mc_minus1_pairs_items.csv.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Building item-level details for flipped pairs (means and deviations)...\")\n",
                "\n",
                "flip_details = []\n",
                "\n",
                "for _, row in df_flip_pairs.iterrows():\n",
                "    target_user = row['TargetUser']\n",
                "    other_user = row['OtherUser']\n",
                "    \n",
                "    t_items = user_item_ratings.get(target_user, {})\n",
                "    o_items = user_item_ratings.get(other_user, {})\n",
                "    \n",
                "    common_items = set(t_items.keys()) & set(o_items.keys())\n",
                "    \n",
                "    t_mean = user_means.get(target_user, 0.0)\n",
                "    o_mean = user_means.get(other_user, 0.0)\n",
                "    \n",
                "    for item in common_items:\n",
                "        t_rating = t_items[item]\n",
                "        o_rating = o_items[item]\n",
                "        \n",
                "        t_dev = t_rating - t_mean\n",
                "        o_dev = o_rating - o_mean\n",
                "        \n",
                "        flip_details.append({\n",
                "            'TargetUser': target_user,\n",
                "            'OtherUser': other_user,\n",
                "            'ItemID': item,\n",
                "            \n",
                "            'RawCosineSimilarity': row['Similarity'],\n",
                "            'MeanCenteredSimilarity': row['MeanCenteredSimilarity'],\n",
                "            'CommonItemsCount': row['CommonItems'],\n",
                "            \n",
                "            'TargetRating': t_rating,\n",
                "            'OtherRating': o_rating,\n",
                "            \n",
                "            'TargetUserMean': t_mean,\n",
                "            'OtherUserMean': o_mean,\n",
                "            \n",
                "            'TargetDeviation': t_dev,\n",
                "            'OtherDeviation': o_dev\n",
                "        })\n",
                "\n",
                "df_flip_details = pd.DataFrame(flip_details)\n",
                "\n",
                "print(f\"Built item-level details for {len(df_flip_details)} (user, item) rows.\")\n",
                "print(df_flip_details.head())\n",
                "\n",
                "flip_details_output_file = '../../results/3_2_1_2_9_raw_high_mc_minus1_pairs_items.csv'\n",
                "df_flip_details.to_csv(flip_details_output_file, index=False)\n",
                "print(f\"Item-level flipped similarity details saved successfully to {flip_details_output_file}.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Case Study 3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.3.1\n",
                "\n",
                "This section defines a function to compute Pearson Correlation Coefficient (PCC) similarity between two users based on their common rated items.  \n",
                "\n",
                "It then calculates PCC similarities for all user pairs in `df_co_users`, saves all results to:  \n",
                "`3_2_1_3_1_user_similarities_pearson.csv`  \n",
                "and a filtered version with `CommonItems > 1` to:  \n",
                "`3_2_1_3_1_user_similarities_pearson_filtered.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_pearson_similarity(user1, user2, user_ratings):\n",
                "    u1_items = user_ratings.get(user1, {})\n",
                "    u2_items = user_ratings.get(user2, {})\n",
                "\n",
                "    common_items = set(u1_items.keys()) & set(u2_items.keys())\n",
                "\n",
                "    if not common_items:\n",
                "        return 0.0, 0\n",
                "\n",
                "    u1_ratings = []\n",
                "    for i in common_items:\n",
                "        u1_ratings.append(u1_items[i])\n",
                "\n",
                "    u2_ratings = []\n",
                "    for i in common_items:\n",
                "        u2_ratings.append(u2_items[i])\n",
                "\n",
                "\n",
                "    mean1 = sum(u1_ratings) / len(u1_ratings)\n",
                "    mean2 = sum(u2_ratings) / len(u2_ratings)\n",
                "\n",
                "    numerator = 0.0\n",
                "    denom1 = 0.0\n",
                "    denom2 = 0.0\n",
                "\n",
                "    for item in common_items:\n",
                "        d1 = u1_items[item] - mean1\n",
                "        d2 = u2_items[item] - mean2\n",
                "\n",
                "        numerator += d1 * d2\n",
                "        denom1 += d1 ** 2\n",
                "        denom2 += d2 ** 2\n",
                "\n",
                "    if denom1 == 0 or denom2 == 0:\n",
                "        return 0.0, len(common_items)\n",
                "\n",
                "    similarity = numerator / ((denom1 ** 0.5) * (denom2 ** 0.5))\n",
                "\n",
                "    return similarity, len(common_items)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating Pearson (PCC) similarities...\n",
                        "Pearson similarity calculation complete.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Calculating Pearson (PCC) similarities...\")\n",
                "pcc_similarities = []\n",
                "\n",
                "for index, row in df_co_users.iterrows():\n",
                "    target_user = row['TargetUser']\n",
                "    other_user = row['OtherUser']\n",
                "    \n",
                "    sim, num_common = calculate_pearson_similarity(\n",
                "        target_user,\n",
                "        other_user,\n",
                "        user_item_ratings\n",
                "    )\n",
                "    \n",
                "    pcc_similarities.append({\n",
                "        'TargetUser': target_user,\n",
                "        'OtherUser': other_user,\n",
                "        'PearsonSimilarity': round(sim, 2), \n",
                "        'CommonItems': num_common\n",
                "    })\n",
                "\n",
                "print(\"Pearson similarity calculation complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saving Pearson similarity results...\n",
                        "Pearson similarities saved successfully.\n",
                        "       TargetUser       OtherUser  PearsonSimilarity  CommonItems\n",
                        "0  A1ER5AYS3FQ9O3   AAP7PPBU72QFM                0.0            1\n",
                        "1  A1ER5AYS3FQ9O3   AIMPBO9K5SQ5X                0.0            1\n",
                        "2  A1ER5AYS3FQ9O3  A2QCVDCCZ3ABAC                0.0            1\n",
                        "3  A1ER5AYS3FQ9O3  A1C0Y8AFKTIRWY                0.0            1\n",
                        "4  A1ER5AYS3FQ9O3  A3M96C2MSACALP                0.0            1\n",
                        "         TargetUser       OtherUser  PearsonSimilarity  CommonItems\n",
                        "52   A1ER5AYS3FQ9O3  A2JCJJNY43QQIV                0.0            3\n",
                        "55   A1ER5AYS3FQ9O3   AM9APPMIE1BHZ                1.0            3\n",
                        "87   A1ER5AYS3FQ9O3  A37PV5GMP2ILJC                0.0            2\n",
                        "93   A1ER5AYS3FQ9O3  A259HHYBP6ZNJ3                0.0            2\n",
                        "124  A1ER5AYS3FQ9O3   A680RUE1FDO8B                0.0            2\n",
                        "Filtered Pearson similarities saved successfully.\n",
                        "         TargetUser       OtherUser  PearsonSimilarity  CommonItems\n",
                        "52   A1ER5AYS3FQ9O3  A2JCJJNY43QQIV                0.0            3\n",
                        "55   A1ER5AYS3FQ9O3   AM9APPMIE1BHZ                1.0            3\n",
                        "87   A1ER5AYS3FQ9O3  A37PV5GMP2ILJC                0.0            2\n",
                        "93   A1ER5AYS3FQ9O3  A259HHYBP6ZNJ3                0.0            2\n",
                        "124  A1ER5AYS3FQ9O3   A680RUE1FDO8B                0.0            2\n"
                    ]
                }
            ],
            "source": [
                "print(\"Saving Pearson similarity results...\")\n",
                "df_pcc_results = pd.DataFrame(pcc_similarities)\n",
                "df_pcc_results.to_csv('../../results/3_2_1_3_1_user_similarities_pearson.csv', index=False)\n",
                "print(\"Pearson similarities saved successfully.\")\n",
                "print(df_pcc_results.head())\n",
                "\n",
                "df_pcc_results_filtered = df_pcc_results[df_pcc_results['CommonItems'] > 1]\n",
                "print(df_pcc_results_filtered.head())\n",
                "\n",
                "df_pcc_results_filtered.to_csv('../../results/3_2_1_3_1_user_similarities_pearson_filtered.csv', index=False)\n",
                "print(\"Filtered Pearson similarities saved successfully.\")\n",
                "print(df_pcc_results_filtered.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.3.2\n",
                "\n",
                "This section selects the top 20% most similar user pairs for each target user using Pearson similarity scores.  \n",
                "\n",
                "The selected pairs are saved to:  \n",
                "`3_2_1_3_2_top_similar_users_pearson.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Identifying top 20% similar users based on Pearson similarity...\n",
                        "Identified 21 top similar user pairs (Pearson).\n",
                        "Saving top 20% Pearson similar users to ../../results/3_2_1_3_2_top_similar_users_pearson.csv...\n",
                        "Top 20% Pearson users saved successfully.\n",
                        "          TargetUser       OtherUser  PearsonSimilarity  CommonItems\n",
                        "1956  A1ER5AYS3FQ9O3   AWPN47SSWK1JV                1.0            3\n",
                        "1216  A1ER5AYS3FQ9O3  A3SEBFKE82AFF0                1.0            2\n",
                        "4905  A1ER5AYS3FQ9O3  A19YOYY7FLQMA6                1.0            2\n",
                        "55    A1ER5AYS3FQ9O3   AM9APPMIE1BHZ                1.0            3\n",
                        "902   A1ER5AYS3FQ9O3  A2QDOJFFLFGF18                1.0            2\n"
                    ]
                }
            ],
            "source": [
                "print(\"Identifying top 20% similar users based on Pearson similarity...\")\n",
                "\n",
                "df_top_pcc_users = get_top_n_similar_users(df_pcc_results_filtered,n_percentage=0.20,similarity_col='PearsonSimilarity')\n",
                "\n",
                "print(f\"Identified {len(df_top_pcc_users)} top similar user pairs (Pearson).\")\n",
                "\n",
                "top_pcc_output_file = '../../results/3_2_1_3_2_top_similar_users_pearson.csv'\n",
                "print(f\"Saving top 20% Pearson similar users to {top_pcc_output_file}...\")\n",
                "\n",
                "df_top_pcc_users.to_csv(top_pcc_output_file, index=False)\n",
                "\n",
                "print(\"Top 20% Pearson users saved successfully.\")\n",
                "print(df_top_pcc_users.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.3.3\n",
                "\n",
                "This section predicts ratings for unrated items using the weighted Pearson similarity values from the top similar users. \n",
                " \n",
                "The prediction results are saved to:  \n",
                "`3_2_1_3_3_predictions_pearson.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting unknown ratings using Pearson similarity...\n",
                        "Generated 1125 predictions (Pearson).\n",
                        "Saving Pearson-based predictions to ../../results/3_2_1_3_3_predictions_pearson.csv...\n",
                        "Pearson-based predictions saved successfully.\n",
                        "       TargetUser        Item  PredictedRating     SimilarityType\n",
                        "0  A1ER5AYS3FQ9O3  B00MCVPIJI              3.0  PearsonSimilarity\n",
                        "1  A1ER5AYS3FQ9O3  B000ND75BG              5.0  PearsonSimilarity\n",
                        "2  A1ER5AYS3FQ9O3  B005ZG0IME              2.0  PearsonSimilarity\n",
                        "3  A1ER5AYS3FQ9O3  B01FFRD1NU              5.0  PearsonSimilarity\n",
                        "4  A1ER5AYS3FQ9O3  B00H888AMC              4.0  PearsonSimilarity\n"
                    ]
                }
            ],
            "source": [
                "print(\"Predicting unknown ratings using Pearson similarity...\")\n",
                "\n",
                "df_predictions_pcc = predict_ratings(df_top_pcc_users,user_item_ratings,sim_col='PearsonSimilarity')\n",
                "\n",
                "print(f\"Generated {len(df_predictions_pcc)} predictions (Pearson).\")\n",
                "\n",
                "predictions_pcc_file = '../../results/3_2_1_3_3_predictions_pearson.csv'\n",
                "print(f\"Saving Pearson-based predictions to {predictions_pcc_file}...\")\n",
                "\n",
                "df_predictions_pcc.to_csv(predictions_pcc_file, index=False)\n",
                "\n",
                "print(\"Pearson-based predictions saved successfully.\")\n",
                "print(df_predictions_pcc.head())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.3.4\n",
                "\n",
                "This section applies the Discounted Similarity (DS) adjustment to the Pearson similarity values, using a discount factor based on the number of common rated items.  \n",
                "\n",
                "The resulting discounted Pearson similarities are saved to:  \n",
                "`3_2_1_3_4_discounted_similarity_pearson.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating Discounted Pearson Similarity...\n",
                        "PCC-based DS calculation complete.\n",
                        "       TargetUser       OtherUser  PearsonSimilarity  CommonItems  \\\n",
                        "0  A1ER5AYS3FQ9O3  A2JCJJNY43QQIV                0.0            3   \n",
                        "1  A1ER5AYS3FQ9O3   AM9APPMIE1BHZ                1.0            3   \n",
                        "2  A1ER5AYS3FQ9O3  A37PV5GMP2ILJC                0.0            2   \n",
                        "3  A1ER5AYS3FQ9O3  A259HHYBP6ZNJ3                0.0            2   \n",
                        "4  A1ER5AYS3FQ9O3   A680RUE1FDO8B                0.0            2   \n",
                        "\n",
                        "   DiscountFactor  DiscountedSimilarity  \n",
                        "0            0.21                  0.00  \n",
                        "1            0.21                  0.21  \n",
                        "2            0.14                  0.00  \n",
                        "3            0.14                  0.00  \n",
                        "4            0.14                  0.00  \n",
                        "Saving Discounted Pearson Similarity to ../../results/3_2_1_3_4_discounted_similarity_pearson.csv...\n",
                        "Discounted Pearson Similarity saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Calculating Discounted Pearson Similarity...\")\n",
                "\n",
                "df_ds_pcc = calculate_discounted_similarity(df_pcc_results_filtered,user_item_ratings,beta_pct=0.3,sim_col='PearsonSimilarity')\n",
                "\n",
                "print(\"PCC-based DS calculation complete.\")\n",
                "print(df_ds_pcc.head())\n",
                "\n",
                "ds_pcc_output_file = '../../results/3_2_1_3_4_discounted_similarity_pearson.csv'\n",
                "print(f\"Saving Discounted Pearson Similarity to {ds_pcc_output_file}...\")\n",
                "\n",
                "df_ds_pcc.to_csv(ds_pcc_output_file, index=False)\n",
                "\n",
                "print(\"Discounted Pearson Similarity saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.3.5\n",
                "\n",
                "This section selects the top 20% most similar user pairs for each target user using Discounted Pearson Similarity values.  \n",
                "\n",
                "The selected top user pairs are saved to:  \n",
                "`3_2_1_3_5_top_similar_users_pearson_ds.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Identifying top 20% similar users based on Discounted Pearson Similarity...\n",
                        "Identified 21 top similar user pairs (PCC DS).\n",
                        "Saving top 20% PCC DS users to ../../results/3_2_1_3_5_top_similar_users_pearson_ds.csv...\n",
                        "Top PCC DS users saved successfully.\n",
                        "        TargetUser       OtherUser  PearsonSimilarity  CommonItems  \\\n",
                        "54  A1ER5AYS3FQ9O3   AWPN47SSWK1JV                1.0            3   \n",
                        "48  A1ER5AYS3FQ9O3  A240FRPD4MEXND                1.0            3   \n",
                        "71  A1ER5AYS3FQ9O3  A2CVXUY1EYQGGA                1.0            3   \n",
                        "1   A1ER5AYS3FQ9O3   AM9APPMIE1BHZ                1.0            3   \n",
                        "17  A1ER5AYS3FQ9O3  A3V6Z4RCDGRC44                1.0            3   \n",
                        "\n",
                        "    DiscountFactor  DiscountedSimilarity  \n",
                        "54            0.21                  0.21  \n",
                        "48            0.21                  0.21  \n",
                        "71            0.21                  0.21  \n",
                        "1             0.21                  0.21  \n",
                        "17            0.21                  0.21  \n"
                    ]
                }
            ],
            "source": [
                "print(\"Identifying top 20% similar users based on Discounted Pearson Similarity...\")\n",
                "\n",
                "df_top_ds_pcc_users = get_top_n_similar_users(df_ds_pcc,n_percentage=0.20,similarity_col='DiscountedSimilarity')\n",
                "\n",
                "print(f\"Identified {len(df_top_ds_pcc_users)} top similar user pairs (PCC DS).\")\n",
                "\n",
                "top_ds_pcc_output_file = '../../results/3_2_1_3_5_top_similar_users_pearson_ds.csv'\n",
                "print(f\"Saving top 20% PCC DS users to {top_ds_pcc_output_file}...\")\n",
                "\n",
                "df_top_ds_pcc_users.to_csv(top_ds_pcc_output_file, index=False)\n",
                "\n",
                "print(\"Top PCC DS users saved successfully.\")\n",
                "print(df_top_ds_pcc_users.head())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.3.6\n",
                "\n",
                "This section generates rating predictions for unrated items using Discounted Pearson Similarity values from the top similar users.  \n",
                "\n",
                "The resulting predictions are saved to:  \n",
                "`3_2_1_3_6_predictions_pearson_ds.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting unknown ratings using Discounted Pearson Similarity...\n",
                        "Generated 1125 predictions (PCC DS).\n",
                        "Saving PCC DS-based predictions to ../../results/3_2_1_3_6_predictions_pearson_ds.csv...\n",
                        "PCC DS-based predictions saved successfully.\n",
                        "       TargetUser        Item  PredictedRating        SimilarityType\n",
                        "0  A1ER5AYS3FQ9O3  B00MCVPIJI              3.0  DiscountedSimilarity\n",
                        "1  A1ER5AYS3FQ9O3  B000ND75BG              5.0  DiscountedSimilarity\n",
                        "2  A1ER5AYS3FQ9O3  B005ZG0IME              2.0  DiscountedSimilarity\n",
                        "3  A1ER5AYS3FQ9O3  B01FFRD1NU              5.0  DiscountedSimilarity\n",
                        "4  A1ER5AYS3FQ9O3  B00H888AMC              4.0  DiscountedSimilarity\n"
                    ]
                }
            ],
            "source": [
                "print(\"Predicting unknown ratings using Discounted Pearson Similarity...\")\n",
                "\n",
                "df_predictions_ds_pcc = predict_ratings(df_top_ds_pcc_users,user_item_ratings,sim_col='DiscountedSimilarity')\n",
                "\n",
                "print(f\"Generated {len(df_predictions_ds_pcc)} predictions (PCC DS).\")\n",
                "\n",
                "predictions_ds_pcc_file = '../../results/3_2_1_3_6_predictions_pearson_ds.csv'\n",
                "print(f\"Saving PCC DS-based predictions to {predictions_ds_pcc_file}...\")\n",
                "\n",
                "df_predictions_ds_pcc.to_csv(predictions_ds_pcc_file, index=False)\n",
                "\n",
                "print(\"PCC DS-based predictions saved successfully.\")\n",
                "print(df_predictions_ds_pcc.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.3.7\n",
                "\n",
                "This section compares the top similar users selected using Pearson similarity versus Discounted Pearson similarity.  \n",
                "\n",
                "It measures how many users appear in both lists (overlap), calculates overlap percentages for each target user, and saves:\n",
                "\n",
                "- Detailed overlap entries to:  \n",
                "  `3_2_1_3_7_overlap_users_pearson.csv`\n",
                "- Summary comparison statistics to:  \n",
                "  `3_2_1_3_7_comparison_results_pearson.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing top users lists (PCC)...\n",
                        "Average Overlap Percentage (PCC): 71.43%\n",
                        "       TargetUser  PCCCount  PCC_DSCount  OverlapCount  OverlapPercentage\n",
                        "0  A1ER5AYS3FQ9O3        21           21            15              71.43\n",
                        "Total overlapping (TargetUser, OtherUser) pairs (PCC): 15\n",
                        "       TargetUser       OtherUser\n",
                        "0  A1ER5AYS3FQ9O3  A2CVXUY1EYQGGA\n",
                        "1  A1ER5AYS3FQ9O3   A1VQHH85U7PX0\n",
                        "2  A1ER5AYS3FQ9O3  A2QDOJFFLFGF18\n",
                        "3  A1ER5AYS3FQ9O3  A19YOYY7FLQMA6\n",
                        "4  A1ER5AYS3FQ9O3   AWPN47SSWK1JV\n",
                        "Intersection users (PCC) with details saved successfully to ../../results/3_2_1_3_7_overlap_users_pearson.csv.\n",
                        "       TargetUser       OtherUser  PearsonSimilarity  CommonItems  \\\n",
                        "0  A1ER5AYS3FQ9O3  A2CVXUY1EYQGGA                1.0            3   \n",
                        "1  A1ER5AYS3FQ9O3   A1VQHH85U7PX0                1.0            2   \n",
                        "2  A1ER5AYS3FQ9O3  A2QDOJFFLFGF18                1.0            2   \n",
                        "3  A1ER5AYS3FQ9O3  A19YOYY7FLQMA6                1.0            2   \n",
                        "4  A1ER5AYS3FQ9O3   AWPN47SSWK1JV                1.0            3   \n",
                        "\n",
                        "   DiscountFactor  DiscountedSimilarity  \n",
                        "0            0.21                  0.21  \n",
                        "1            0.14                  0.14  \n",
                        "2            0.14                  0.14  \n",
                        "3            0.14                  0.14  \n",
                        "4            0.21                  0.21  \n",
                        "PCC comparison results saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Comparing top users lists (PCC)...\")\n",
                "pcc_comparison_results = []\n",
                "pcc_overlap_pairs = []\n",
                "\n",
                "all_target_users_pcc = set(df_top_pcc_users['TargetUser']).union(\n",
                "    set(df_top_ds_pcc_users['TargetUser'])\n",
                ")\n",
                "\n",
                "for target_user in all_target_users_pcc:\n",
                "    top_users_pcc = set(\n",
                "        df_top_pcc_users[df_top_pcc_users['TargetUser'] == target_user]['OtherUser']\n",
                "    )\n",
                "    top_users_ds_pcc = set(\n",
                "        df_top_ds_pcc_users[df_top_ds_pcc_users['TargetUser'] == target_user]['OtherUser']\n",
                "    )\n",
                "    \n",
                "    overlap = top_users_pcc.intersection(top_users_ds_pcc)\n",
                "    overlap_count = len(overlap)\n",
                "\n",
                "    for other_user in overlap:\n",
                "        pcc_overlap_pairs.append({\n",
                "            'TargetUser': target_user,\n",
                "            'OtherUser': other_user\n",
                "        })\n",
                "\n",
                "    pcc_comparison_results.append({\n",
                "        'TargetUser': target_user,\n",
                "        'PCCCount': len(top_users_pcc),\n",
                "        'PCC_DSCount': len(top_users_ds_pcc),\n",
                "        'OverlapCount': overlap_count,\n",
                "        'OverlapPercentage': round(overlap_count / len(top_users_pcc) * 100, 2)\n",
                "                            if len(top_users_pcc) > 0 else 0\n",
                "    })\n",
                "\n",
                "df_pcc_comparison = pd.DataFrame(pcc_comparison_results)\n",
                "print(f\"Average Overlap Percentage (PCC): {df_pcc_comparison['OverlapPercentage'].mean():.2f}%\")\n",
                "print(df_pcc_comparison.head())\n",
                "\n",
                "df_pcc_overlap_keys = pd.DataFrame(pcc_overlap_pairs)\n",
                "\n",
                "print(f\"Total overlapping (TargetUser, OtherUser) pairs (PCC): {len(df_pcc_overlap_keys)}\")\n",
                "print(df_pcc_overlap_keys.head())\n",
                "\n",
                "df_pcc_overlap_details = pd.merge(\n",
                "    df_pcc_overlap_keys,\n",
                "    df_ds_pcc, \n",
                "    on=['TargetUser', 'OtherUser'],\n",
                "    how='left'\n",
                ")\n",
                "\n",
                "overlap_pcc_output_file = '../../results/3_2_1_3_7_overlap_users_pearson.csv'\n",
                "df_pcc_overlap_details.to_csv(overlap_pcc_output_file, index=False)\n",
                "print(f\"Intersection users (PCC) with details saved successfully to {overlap_pcc_output_file}.\")\n",
                "print(df_pcc_overlap_details.head())\n",
                "\n",
                "comparison_pcc_output_file = '../../results/3_2_1_3_7_comparison_results_pearson.csv'\n",
                "df_pcc_comparison.to_csv(comparison_pcc_output_file, index=False)\n",
                "print(\"PCC comparison results saved successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.3.8\n",
                "\n",
                "This section compares prediction values generated using Pearson similarity vs. Discounted Pearson similarity (DS) for the same (TargetUser, Item) pairs.\n",
                "  \n",
                "It calculates the difference for each pair and saves the comparison results to:  \n",
                "`3_2_1_3_8_pred_comparison_pearson.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Comparing rating predictions (PCC)...\n",
                        "Compared 1125 common predictions (PCC).\n",
                        "Average Difference: 0.0016\n",
                        "       TargetUser        Item  PredictedRating_PCC  PredictedRating_PCC_DS  \\\n",
                        "0  A1ER5AYS3FQ9O3  B00MCVPIJI                  3.0                     3.0   \n",
                        "1  A1ER5AYS3FQ9O3  B000ND75BG                  5.0                     5.0   \n",
                        "2  A1ER5AYS3FQ9O3  B005ZG0IME                  2.0                     2.0   \n",
                        "3  A1ER5AYS3FQ9O3  B01FFRD1NU                  5.0                     5.0   \n",
                        "4  A1ER5AYS3FQ9O3  B00H888AMC                  4.0                     4.0   \n",
                        "\n",
                        "   Difference  \n",
                        "0         0.0  \n",
                        "1         0.0  \n",
                        "2         0.0  \n",
                        "3         0.0  \n",
                        "4         0.0  \n",
                        "PCC predictions comparison saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Comparing rating predictions (PCC)...\")\n",
                "\n",
                "df_pred_comparison_pcc = pd.merge(\n",
                "    df_predictions_pcc[['TargetUser', 'Item', 'PredictedRating']],\n",
                "    df_predictions_ds_pcc[['TargetUser', 'Item', 'PredictedRating']],\n",
                "    on=['TargetUser', 'Item'],\n",
                "    suffixes=('_PCC', '_PCC_DS'),\n",
                "    how='inner'\n",
                ")\n",
                "\n",
                "df_pred_comparison_pcc['Difference'] = \\\n",
                "    df_pred_comparison_pcc['PredictedRating_PCC'] - df_pred_comparison_pcc['PredictedRating_PCC_DS']\n",
                "\n",
                "print(f\"Compared {len(df_pred_comparison_pcc)} common predictions (PCC).\")\n",
                "print(f\"Average Difference: {df_pred_comparison_pcc['Difference'].abs().mean():.4f}\")\n",
                "print(df_pred_comparison_pcc.head())\n",
                "\n",
                "pred_comp_pcc_output = '../../results/3_2_1_3_8_pred_comparison_pearson.csv'\n",
                "df_pred_comparison_pcc.to_csv(pred_comp_pcc_output, index=False)\n",
                "\n",
                "print(\"PCC predictions comparison saved successfully.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2.1.3.9\n",
                "\n",
                "This section finds user pairs whose cosine similarity is positive while their Pearson similarity is negative, saves these pair-level results to:  \n",
                "`3_2_1_3_9_cosine_pos_pearson_neg_pairs.csv`  \n",
                "\n",
                "It then builds item-level details for these pairs (including ratings, pair-wise means, and deviations) and saves them to:  \n",
                "`3_2_1_3_9_cosine_pos_pearson_neg_pairs_items.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Finding user pairs where cosine is +ve but Pearson correlation is negative...\n",
                        "Found 7 user pairs with cosine > 0.0 and Pearson < 0.\n",
                        "        TargetUser       OtherUser  Similarity  CommonItems  PearsonSimilarity\n",
                        "13  A1ER5AYS3FQ9O3  A2WB7LZ595CR50        0.94            2               -1.0\n",
                        "24  A1ER5AYS3FQ9O3  A32O5FZH994CNY        0.98            3               -1.0\n",
                        "31  A1ER5AYS3FQ9O3   AMRMK86X3PKXD        0.98            2               -1.0\n",
                        "67  A1ER5AYS3FQ9O3  A2RUN9WBD5H23R        0.98            2               -1.0\n",
                        "73  A1ER5AYS3FQ9O3   AW8ESDU0C82O0        0.88            2               -1.0\n",
                        "Cosine-positive / Pearson-negative pairs saved successfully to ../../results/3_2_1_3_9_cosine_pos_pearson_neg_pairs.csv.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Finding user pairs where cosine is +ve but Pearson correlation is negative...\")\n",
                "\n",
                "COSINE_POS_THRESHOLD = 0.0 \n",
                "\n",
                "df_merged_pcc = pd.merge(\n",
                "    df_results_filtered[['TargetUser', 'OtherUser', 'Similarity', 'CommonItems']],\n",
                "    df_pcc_results_filtered[['TargetUser', 'OtherUser', 'PearsonSimilarity']],\n",
                "    on=['TargetUser', 'OtherUser'],\n",
                "    how='inner'\n",
                ")\n",
                "\n",
                "df_cos_pos_pcc_neg_pairs = df_merged_pcc[\n",
                "    (df_merged_pcc['Similarity'] > COSINE_POS_THRESHOLD) &\n",
                "    (df_merged_pcc['PearsonSimilarity'] < 0)\n",
                "].copy()\n",
                "\n",
                "print(f\"Found {len(df_cos_pos_pcc_neg_pairs)} user pairs with cosine > {COSINE_POS_THRESHOLD} and Pearson < 0.\")\n",
                "print(df_cos_pos_pcc_neg_pairs.head())\n",
                "\n",
                "pairs_output_file = '../../results/3_2_1_3_9_cosine_pos_pearson_neg_pairs.csv'\n",
                "df_cos_pos_pcc_neg_pairs.to_csv(pairs_output_file, index=False)\n",
                "print(f\"Cosine-positive / Pearson-negative pairs saved successfully to {pairs_output_file}.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building item-level details for cosine-positive / Pearson-negative pairs...\n",
                        "Built item-level details for 16 (user, item) rows.\n",
                        "       TargetUser       OtherUser      ItemID  CosineSimilarity  \\\n",
                        "0  A1ER5AYS3FQ9O3  A2WB7LZ595CR50  B004HKJTT2              0.94   \n",
                        "1  A1ER5AYS3FQ9O3  A2WB7LZ595CR50  B00L3KW09K              0.94   \n",
                        "2  A1ER5AYS3FQ9O3  A32O5FZH994CNY  B001AAN4PW              0.98   \n",
                        "3  A1ER5AYS3FQ9O3  A32O5FZH994CNY  B001AAOZHI              0.98   \n",
                        "4  A1ER5AYS3FQ9O3  A32O5FZH994CNY  B004L62KIO              0.98   \n",
                        "\n",
                        "   PearsonSimilarity  CommonItemsCount  TargetRating  OtherRating  \\\n",
                        "0               -1.0                 2           4.0          5.0   \n",
                        "1               -1.0                 2           5.0          3.0   \n",
                        "2               -1.0                 3           4.0          5.0   \n",
                        "3               -1.0                 3           4.0          5.0   \n",
                        "4               -1.0                 3           5.0          4.0   \n",
                        "\n",
                        "   TargetMean_CommonItems  OtherMean_CommonItems  TargetDeviation_CommonItems  \\\n",
                        "0                4.500000               4.000000                    -0.500000   \n",
                        "1                4.500000               4.000000                     0.500000   \n",
                        "2                4.333333               4.666667                    -0.333333   \n",
                        "3                4.333333               4.666667                    -0.333333   \n",
                        "4                4.333333               4.666667                     0.666667   \n",
                        "\n",
                        "   OtherDeviation_CommonItems  \n",
                        "0                    1.000000  \n",
                        "1                   -1.000000  \n",
                        "2                    0.333333  \n",
                        "3                    0.333333  \n",
                        "4                   -0.666667  \n",
                        "Item-level cosine-positive / Pearson-negative details saved successfully to ../../results/3_2_1_3_9_cosine_pos_pearson_neg_pairs_items.csv.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Building item-level details for cosine-positive / Pearson-negative pairs...\")\n",
                "\n",
                "pcc_flip_details = []\n",
                "\n",
                "for _, row in df_cos_pos_pcc_neg_pairs.iterrows():\n",
                "    target_user = row['TargetUser']\n",
                "    other_user = row['OtherUser']\n",
                "    \n",
                "    t_items = user_item_ratings.get(target_user, {})\n",
                "    o_items = user_item_ratings.get(other_user, {})\n",
                "    \n",
                "    common_items = set(t_items.keys()) & set(o_items.keys())\n",
                "    if not common_items:\n",
                "        continue\n",
                "    \n",
                "    t_common_ratings = []\n",
                "    o_common_ratings = []\n",
                "    for item in common_items:\n",
                "        t_common_ratings.append(t_items[item])\n",
                "        o_common_ratings.append(o_items[item])\n",
                "    \n",
                "    t_mean_pair = sum(t_common_ratings) / len(t_common_ratings)\n",
                "    o_mean_pair = sum(o_common_ratings) / len(o_common_ratings)\n",
                "    \n",
                "    for item in common_items:\n",
                "        t_rating = t_items[item]\n",
                "        o_rating = o_items[item]\n",
                "        \n",
                "        t_dev_pair = t_rating - t_mean_pair\n",
                "        o_dev_pair = o_rating - o_mean_pair\n",
                "        \n",
                "        pcc_flip_details.append({\n",
                "            'TargetUser': target_user,\n",
                "            'OtherUser': other_user,\n",
                "            'ItemID': item,\n",
                "            \n",
                "            'CosineSimilarity': row['Similarity'],\n",
                "            'PearsonSimilarity': row['PearsonSimilarity'],\n",
                "            'CommonItemsCount': row['CommonItems'],\n",
                "            \n",
                "            'TargetRating': t_rating,\n",
                "            'OtherRating': o_rating,\n",
                "            \n",
                "            'TargetMean_CommonItems': t_mean_pair,\n",
                "            'OtherMean_CommonItems': o_mean_pair,\n",
                "            \n",
                "            'TargetDeviation_CommonItems': t_dev_pair,\n",
                "            'OtherDeviation_CommonItems': o_dev_pair,\n",
                "        })\n",
                "\n",
                "df_pcc_flip_details = pd.DataFrame(pcc_flip_details)\n",
                "\n",
                "print(f\"Built item-level details for {len(df_pcc_flip_details)} (user, item) rows.\")\n",
                "print(df_pcc_flip_details.head())\n",
                "\n",
                "pcc_flip_items_output_file = '../../results/3_2_1_3_9_cosine_pos_pearson_neg_pairs_items.csv'\n",
                "df_pcc_flip_details.to_csv(pcc_flip_items_output_file, index=False)\n",
                "print(f\"Item-level cosine-positive / Pearson-negative details saved successfully to {pcc_flip_items_output_file}.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
